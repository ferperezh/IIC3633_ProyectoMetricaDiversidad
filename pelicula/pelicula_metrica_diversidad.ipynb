{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ferperezh/IIC3633_ProyectoMetricaDiversidad/blob/main/pelicula_metrica_diversidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlgUktzAgpDd"
   },
   "source": [
    "# Métrica **Diversidad de Usuario** en la Película"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZGEvrNhg04J"
   },
   "source": [
    "## Importar los datos\n",
    "Es necesario agregar el archivo \"kaggle.json\" disponible en el repositorio al entorno de archivos del Colab:\n",
    "- https://github.com/ferperezh/IIC3633_ProyectoMetricaDiversidad/blob/main/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cyOa1v13lzbj"
   },
   "outputs": [],
   "source": [
    "# Crear el directorio .kaggle en Colab\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "# Mover el archivo kaggle.json al directorio .kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "# Cambiar los permisos del archivo kaggle.json para asegurar privacidad\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voZmyq50pPvk",
    "outputId": "486a1c89-b322-4009-ef21-fb90bdee697a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (4.66.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Obtaining dependency information for python-slugify from https://files.pythonhosted.org/packages/a4/62/02da182e544a51a5c3ccf4b03ab79df279f9c60c5e82d5e8bec7ca26ac11/python_slugify-8.0.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Obtaining dependency information for text-unidecode>=1.3 from https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kaggle) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->kaggle) (3.10)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=19dbc08e6943237c8e29886109b3bc2ef5851a82047ee2ffdf10b08ad4019cf6\n",
      "  Stored in directory: /Users/macbook/Library/Caches/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtEW04WVpTUP",
    "outputId": "7e0a3d4d-e459-410b-e32a-6010cf20976c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading movielens-20m-dataset.zip to /Users/macbook/Desktop/IIC3633_ProyectoMetricaDiversidad\n",
      "100%|███████████████████████████████████████▉| 195M/195M [00:16<00:00, 14.7MB/s]\n",
      "100%|████████████████████████████████████████| 195M/195M [00:16<00:00, 12.8MB/s]\n",
      "Path to dataset files: movielens-20m-dataset\n"
     ]
    }
   ],
   "source": [
    "# Descargar el dataset\n",
    "!kaggle datasets download -d grouplens/movielens-20m-dataset\n",
    "\n",
    "# Descomprimir el archivo zip descargado\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"movielens-20m-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"movielens-20m-dataset\")\n",
    "\n",
    "print(\"Path to dataset files: movielens-20m-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am1WAVqMhLyb"
   },
   "source": [
    "## Procesamiento de Datasets Peliculas\n",
    "Consideramos la tabla `ratings` para tener los ratings que un usuario le da a una pelicula dad. Por lo que obetenemos el promedio de rating que da cada usuario y luego consideramos solo las peliculas que estan sobre el promedio de cada usario. Esas vamos a considerar como las peliculas del usuario. Para luego hacer el join con `movie` mara obtener la metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "baklulfhpbjD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "genome_scores = pd.read_csv('movielens-20m-dataset/genome_scores.csv')\n",
    "genome_tags = pd.read_csv('movielens-20m-dataset/genome_tags.csv')\n",
    "links = pd.read_csv('movielens-20m-dataset/link.csv')\n",
    "movies = pd.read_csv('movielens-20m-dataset/movie.csv')\n",
    "ratings = pd.read_csv('movielens-20m-dataset/rating.csv')\n",
    "tags = pd.read_csv('movielens-20m-dataset/tag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HTopHB3oaEoF"
   },
   "outputs": [],
   "source": [
    "# Agrupar por usuario la tabla raitings para tener el rating promedio que le da a las peliculas\n",
    "ratings_por_usuario = ratings.groupby('userId')['rating'].mean()\n",
    "# Hacemos un round a la decima\n",
    "ratings_por_usuario = ratings_por_usuario.round(1)\n",
    "ratings_por_usuario\n",
    "\n",
    "# Ahora agregamos la columna rating_mean a la tabla rating con esta informacion\n",
    "ratings['rating_mean'] = ratings['userId'].map(ratings_por_usuario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "STDj83WdaFvq"
   },
   "outputs": [],
   "source": [
    "# Filtramos por todos los ratings que son mayor o igual al rating_mean\n",
    "ratings_filtrados = ratings[ratings['rating'] >= ratings['rating_mean']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbTYnKFCaTL4"
   },
   "source": [
    "Ahora las conectamos `ratings_filtrados` con la metada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dWO3XS7oaaC3"
   },
   "outputs": [],
   "source": [
    "#Merge de ratings filtrados con movies\n",
    "movies_data = pd.merge(ratings_filtrados, movies, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "gzXHFjL-apNe",
    "outputId": "b67d035b-3449-4d23-b48a-43810a046d1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating_mean</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-09-10 03:08:54</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Rob Roy (1995)</td>\n",
       "      <td>Action|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:46:13</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Clerks (1994)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:35:40</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Interview with the Vampire: The Vampire Chroni...</td>\n",
       "      <td>Drama|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:33:46</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:31:43</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Léon: The Professional (a.k.a. The Professiona...</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276524</th>\n",
       "      <td>138493</td>\n",
       "      <td>66762</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-10-17 18:50:08</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Paris (2008)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276525</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-12-07 18:15:20</td>\n",
       "      <td>4.2</td>\n",
       "      <td>X-Men Origins: Wolverine (2009)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276526</th>\n",
       "      <td>138493</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-11-13 15:42:00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Up (2009)</td>\n",
       "      <td>Adventure|Animation|Children|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276527</th>\n",
       "      <td>138493</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-12-03 18:31:48</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Transformers: Revenge of the Fallen (2009)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276528</th>\n",
       "      <td>138493</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009-11-13 15:42:24</td>\n",
       "      <td>4.2</td>\n",
       "      <td>District 9 (2009)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276529 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating            timestamp  rating_mean  \\\n",
       "0              1      151     4.0  2004-09-10 03:08:54          3.7   \n",
       "1              1      223     4.0  2005-04-02 23:46:13          3.7   \n",
       "2              1      253     4.0  2005-04-02 23:35:40          3.7   \n",
       "3              1      260     4.0  2005-04-02 23:33:46          3.7   \n",
       "4              1      293     4.0  2005-04-02 23:31:43          3.7   \n",
       "...          ...      ...     ...                  ...          ...   \n",
       "11276524  138493    66762     4.5  2009-10-17 18:50:08          4.2   \n",
       "11276525  138493    68319     4.5  2009-12-07 18:15:20          4.2   \n",
       "11276526  138493    68954     4.5  2009-11-13 15:42:00          4.2   \n",
       "11276527  138493    69526     4.5  2009-12-03 18:31:48          4.2   \n",
       "11276528  138493    70286     5.0  2009-11-13 15:42:24          4.2   \n",
       "\n",
       "                                                      title  \\\n",
       "0                                            Rob Roy (1995)   \n",
       "1                                             Clerks (1994)   \n",
       "2         Interview with the Vampire: The Vampire Chroni...   \n",
       "3                 Star Wars: Episode IV - A New Hope (1977)   \n",
       "4         Léon: The Professional (a.k.a. The Professiona...   \n",
       "...                                                     ...   \n",
       "11276524                                       Paris (2008)   \n",
       "11276525                    X-Men Origins: Wolverine (2009)   \n",
       "11276526                                          Up (2009)   \n",
       "11276527         Transformers: Revenge of the Fallen (2009)   \n",
       "11276528                                  District 9 (2009)   \n",
       "\n",
       "                                      genres  \n",
       "0                   Action|Drama|Romance|War  \n",
       "1                                     Comedy  \n",
       "2                               Drama|Horror  \n",
       "3                    Action|Adventure|Sci-Fi  \n",
       "4                Action|Crime|Drama|Thriller  \n",
       "...                                      ...  \n",
       "11276524                Comedy|Drama|Romance  \n",
       "11276525              Action|Sci-Fi|Thriller  \n",
       "11276526  Adventure|Animation|Children|Drama  \n",
       "11276527        Action|Adventure|Sci-Fi|IMAX  \n",
       "11276528             Mystery|Sci-Fi|Thriller  \n",
       "\n",
       "[11276529 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJ2AjqFqanfV"
   },
   "source": [
    "Vemos que por pelicula tenemos varios generos separados por | . Pero consideremos todos los genermos por separados todos esos generos representan el genero de la pelicula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5pBUW8olbVv8"
   },
   "outputs": [],
   "source": [
    "movies_data['genre_list'] = movies_data['genres'].str.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 878
    },
    "id": "PDqePy5wgZJs",
    "outputId": "b24454c2-9e54-477b-8584-2c887c27e711"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating_mean</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2004-09-10 03:08:54</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Rob Roy (1995)</td>\n",
       "      <td>Action|Drama|Romance|War</td>\n",
       "      <td>[Action, Drama, Romance, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:46:13</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Clerks (1994)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>[Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:35:40</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Interview with the Vampire: The Vampire Chroni...</td>\n",
       "      <td>Drama|Horror</td>\n",
       "      <td>[Drama, Horror]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>260</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:33:46</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Star Wars: Episode IV - A New Hope (1977)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>[Action, Adventure, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2005-04-02 23:31:43</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Léon: The Professional (a.k.a. The Professiona...</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276524</th>\n",
       "      <td>138493</td>\n",
       "      <td>66762</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-10-17 18:50:08</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Paris (2008)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276525</th>\n",
       "      <td>138493</td>\n",
       "      <td>68319</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-12-07 18:15:20</td>\n",
       "      <td>4.2</td>\n",
       "      <td>X-Men Origins: Wolverine (2009)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>[Action, Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276526</th>\n",
       "      <td>138493</td>\n",
       "      <td>68954</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-11-13 15:42:00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Up (2009)</td>\n",
       "      <td>Adventure|Animation|Children|Drama</td>\n",
       "      <td>[Adventure, Animation, Children, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276527</th>\n",
       "      <td>138493</td>\n",
       "      <td>69526</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2009-12-03 18:31:48</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Transformers: Revenge of the Fallen (2009)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|IMAX</td>\n",
       "      <td>[Action, Adventure, Sci-Fi, IMAX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11276528</th>\n",
       "      <td>138493</td>\n",
       "      <td>70286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2009-11-13 15:42:24</td>\n",
       "      <td>4.2</td>\n",
       "      <td>District 9 (2009)</td>\n",
       "      <td>Mystery|Sci-Fi|Thriller</td>\n",
       "      <td>[Mystery, Sci-Fi, Thriller]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11276529 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId  rating            timestamp  rating_mean  \\\n",
       "0              1      151     4.0  2004-09-10 03:08:54          3.7   \n",
       "1              1      223     4.0  2005-04-02 23:46:13          3.7   \n",
       "2              1      253     4.0  2005-04-02 23:35:40          3.7   \n",
       "3              1      260     4.0  2005-04-02 23:33:46          3.7   \n",
       "4              1      293     4.0  2005-04-02 23:31:43          3.7   \n",
       "...          ...      ...     ...                  ...          ...   \n",
       "11276524  138493    66762     4.5  2009-10-17 18:50:08          4.2   \n",
       "11276525  138493    68319     4.5  2009-12-07 18:15:20          4.2   \n",
       "11276526  138493    68954     4.5  2009-11-13 15:42:00          4.2   \n",
       "11276527  138493    69526     4.5  2009-12-03 18:31:48          4.2   \n",
       "11276528  138493    70286     5.0  2009-11-13 15:42:24          4.2   \n",
       "\n",
       "                                                      title  \\\n",
       "0                                            Rob Roy (1995)   \n",
       "1                                             Clerks (1994)   \n",
       "2         Interview with the Vampire: The Vampire Chroni...   \n",
       "3                 Star Wars: Episode IV - A New Hope (1977)   \n",
       "4         Léon: The Professional (a.k.a. The Professiona...   \n",
       "...                                                     ...   \n",
       "11276524                                       Paris (2008)   \n",
       "11276525                    X-Men Origins: Wolverine (2009)   \n",
       "11276526                                          Up (2009)   \n",
       "11276527         Transformers: Revenge of the Fallen (2009)   \n",
       "11276528                                  District 9 (2009)   \n",
       "\n",
       "                                      genres  \\\n",
       "0                   Action|Drama|Romance|War   \n",
       "1                                     Comedy   \n",
       "2                               Drama|Horror   \n",
       "3                    Action|Adventure|Sci-Fi   \n",
       "4                Action|Crime|Drama|Thriller   \n",
       "...                                      ...   \n",
       "11276524                Comedy|Drama|Romance   \n",
       "11276525              Action|Sci-Fi|Thriller   \n",
       "11276526  Adventure|Animation|Children|Drama   \n",
       "11276527        Action|Adventure|Sci-Fi|IMAX   \n",
       "11276528             Mystery|Sci-Fi|Thriller   \n",
       "\n",
       "                                       genre_list  \n",
       "0                   [Action, Drama, Romance, War]  \n",
       "1                                        [Comedy]  \n",
       "2                                 [Drama, Horror]  \n",
       "3                     [Action, Adventure, Sci-Fi]  \n",
       "4                [Action, Crime, Drama, Thriller]  \n",
       "...                                           ...  \n",
       "11276524                 [Comedy, Drama, Romance]  \n",
       "11276525               [Action, Sci-Fi, Thriller]  \n",
       "11276526  [Adventure, Animation, Children, Drama]  \n",
       "11276527        [Action, Adventure, Sci-Fi, IMAX]  \n",
       "11276528              [Mystery, Sci-Fi, Thriller]  \n",
       "\n",
       "[11276529 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGslOVr2dCPw"
   },
   "source": [
    "Luego generemos un dicionario para contar con la lista de generos por pelicula. Donde contamos por usario que categorias son y cuantas. Pero el código demora mucha en correr por lo que se cuardar en el colab.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "id": "Tjo-mlHibhV3",
    "outputId": "e1e89fde-e829-4005-bc94-bbba29fa175c"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Crear un diccionario para contar los géneros de cada usuario\u001b[39;00m\n\u001b[1;32m      2\u001b[0m user_genre_counts \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m movies_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m      5\u001b[0m     user_id \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m     genres \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre_list\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:1554\u001b[0m, in \u001b[0;36mDataFrame.iterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1552\u001b[0m using_cow \u001b[38;5;241m=\u001b[39m using_copy_on_write()\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m-> 1554\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block:\n\u001b[1;32m   1556\u001b[0m         s\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39madd_references(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:439\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    436\u001b[0m data_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    437\u001b[0m original_dtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mExtensionArray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m astype_is_view(data\u001b[38;5;241m.\u001b[39mdtype, pandas_dtype(dtype)):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para contar los géneros de cada usuario\n",
    "user_genre_counts = {}\n",
    "\n",
    "for index, row in movies_data.iterrows():\n",
    "    user_id = row['userId']\n",
    "    genres = row['genre_list']\n",
    "\n",
    "    if user_id not in user_genre_counts:\n",
    "        user_genre_counts[user_id] = {}\n",
    "\n",
    "    for genre in genres:\n",
    "      if genre not in user_genre_counts[user_id]:\n",
    "          user_genre_counts[user_id][genre] =  0\n",
    "      user_genre_counts[user_id][genre] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88iV9RoQc4zN"
   },
   "source": [
    "Debes hacer una conexion con tu colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zvv7QAg5cz_8",
    "outputId": "34771473-61a0-4cbc-9f63-57b22f4d221c"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/IIC3633-2024-2/user_genre_counts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "path = '/content/drive/MyDrive/IIC3633-2024-2/user_genre_counts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Q_nIiiHces47",
    "outputId": "8eea76e8-e2e9-4ef0-c003-345df8d45b20"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\" # Guardar user_genre_counts \\nimport json\\n\\nwith open(path, 'w') as file:\\n    json.dump(user_genre_counts, file) \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' # Guardar user_genre_counts\n",
    "import json\n",
    "\n",
    "with open(path, 'w') as file:\n",
    "    json.dump(user_genre_counts, file) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QM8t2Zqe4Cz"
   },
   "outputs": [],
   "source": [
    "# Obtener user_genre_counts\n",
    "import json\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    user_genre_counts = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMFEX6zypmto"
   },
   "source": [
    "## Categorización de cada usuario\n",
    "Obtenemos el top k=5 de categorias de cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "collapsed": true,
    "id": "RzAFpTE9pr7O",
    "outputId": "3456a922-19df-4ab4-95b8-0f54f71d43a0"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_genre_counts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m top_k_genres_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Itera sobre cada usuario en user\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id, genres \u001b[38;5;129;01min\u001b[39;00m \u001b[43muser_genre_counts\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      7\u001b[0m   \u001b[38;5;66;03m# Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m    sorted_genres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(genres\u001b[38;5;241m.\u001b[39mitems(), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:k]\n\u001b[1;32m      9\u001b[0m    \u001b[38;5;28;01mfor\u001b[39;00m genre, _ \u001b[38;5;129;01min\u001b[39;00m sorted_genres:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_genre_counts' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcular las k categorías más vistas por cada usuario\n",
    "k = 5\n",
    "top_k_genres_data = []\n",
    "\n",
    "# Itera sobre cada usuario en user\n",
    "for user_id, genres in user_genre_counts.items():\n",
    "  # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\n",
    "   sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "   for genre, _ in sorted_genres:\n",
    "    top_k_genres_data.append({\n",
    "        'userId': user_id,\n",
    "        'genre_principal': genre,\n",
    "        'count': genres[genre]\n",
    "    })\n",
    "\n",
    "\n",
    "top_k_5_categories_total = pd.DataFrame(top_k_genres_data)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Top k = 5 géneros más vistos por usuario:\")\n",
    "top_k_5_categories_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rofvl7IXiKfH"
   },
   "source": [
    "# Generar Recomendaciones\n",
    "\n",
    "Se probará con diferentes métodos de recomendación para evaluar los resultados del modelo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE9RoNZUvFxt"
   },
   "source": [
    "## Método Most Popular:\n",
    "Recomienda las peliculas más vistas o mejor rankeadas en el conjunto global de datos de entrenamiento.\n",
    "- Cuenta y ordena las peliculas según número de reproducciones\n",
    "- Selecciona las `k peliculas` más populares\n",
    "- Alta probabilidad de recomendar contenido con hartas visualizaciones\n",
    "- Mismo resultado para todos los usuarios\n",
    "- Baja diversidad de recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff216W1UgoxT",
    "outputId": "44c84a94-c867-4b13-ffc2-9db38ae9b43c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp', 'rating_mean', 'title',\n",
       "       'genres', 'genre_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "irOe5VtQgvkv"
   },
   "outputs": [],
   "source": [
    "data_movie = movies_data[['userId', 'movieId', 'title', 'genre_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NR7XUSqzlj4V",
    "outputId": "afeeebef-c095-4699-a872-a34855667e8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138493"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie['userId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "eC8eKR1pHxlV"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m dict_movie_title_reverse \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m data_movie\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 5\u001b[0m     movie_id \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      6\u001b[0m     title \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     dict_movie_title[movie_id] \u001b[38;5;241m=\u001b[39m title\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m casted_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_indexer(key)\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Poner diccionario para que el movieid sea igual a tittle\n",
    "dict_movie_title = {}\n",
    "dict_movie_title_reverse = {}\n",
    "for index, row in data_movie.iterrows():\n",
    "    movie_id = row['movieId']\n",
    "    title = row['title']\n",
    "    dict_movie_title[movie_id] = title\n",
    "    dict_movie_title_reverse[title] = movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rmy66VM13nB0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Filtrar usuarios con al menos 2 filas\n",
    "user_counts = data_movie['userId'].value_counts()\n",
    "valid_users = user_counts[user_counts > 1].index\n",
    "filtered_data = data_movie[data_movie['userId'].isin(valid_users)]\n",
    "\n",
    "data_movie_train, data_movie_test = train_test_split(\n",
    "    filtered_data,\n",
    "    test_size=0.2,\n",
    "    stratify=filtered_data['userId'],  # Stratificar por `userId`\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "q3sVRhbCgR-i",
    "outputId": "b0c7db98-f3a7-4f7c-bf7c-83ad3ca76a03"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genre_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5629735</th>\n",
       "      <td>69165</td>\n",
       "      <td>2997</td>\n",
       "      <td>Being John Malkovich (1999)</td>\n",
       "      <td>[Comedy, Drama, Fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860377</th>\n",
       "      <td>10412</td>\n",
       "      <td>2617</td>\n",
       "      <td>Mummy, The (1999)</td>\n",
       "      <td>[Action, Adventure, Comedy, Fantasy, Horror, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754589</th>\n",
       "      <td>119686</td>\n",
       "      <td>1282</td>\n",
       "      <td>Fantasia (1940)</td>\n",
       "      <td>[Animation, Children, Fantasy, Musical]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4315380</th>\n",
       "      <td>52860</td>\n",
       "      <td>3147</td>\n",
       "      <td>Green Mile, The (1999)</td>\n",
       "      <td>[Crime, Drama]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316268</th>\n",
       "      <td>28060</td>\n",
       "      <td>1234</td>\n",
       "      <td>Sting, The (1973)</td>\n",
       "      <td>[Comedy, Crime]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7305429</th>\n",
       "      <td>89542</td>\n",
       "      <td>2716</td>\n",
       "      <td>Ghostbusters (a.k.a. Ghost Busters) (1984)</td>\n",
       "      <td>[Action, Comedy, Sci-Fi]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5689997</th>\n",
       "      <td>69916</td>\n",
       "      <td>7161</td>\n",
       "      <td>Cheaper by the Dozen (2003)</td>\n",
       "      <td>[Children, Comedy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023935</th>\n",
       "      <td>74055</td>\n",
       "      <td>1222</td>\n",
       "      <td>Full Metal Jacket (1987)</td>\n",
       "      <td>[Drama, War]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471978</th>\n",
       "      <td>54819</td>\n",
       "      <td>8530</td>\n",
       "      <td>Dear Frankie (2004)</td>\n",
       "      <td>[Drama, Romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9875772</th>\n",
       "      <td>121229</td>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story 2 (1999)</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2255305 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId                                       title  \\\n",
       "5629735   69165     2997                 Being John Malkovich (1999)   \n",
       "860377    10412     2617                           Mummy, The (1999)   \n",
       "9754589  119686     1282                             Fantasia (1940)   \n",
       "4315380   52860     3147                      Green Mile, The (1999)   \n",
       "2316268   28060     1234                           Sting, The (1973)   \n",
       "...         ...      ...                                         ...   \n",
       "7305429   89542     2716  Ghostbusters (a.k.a. Ghost Busters) (1984)   \n",
       "5689997   69916     7161                 Cheaper by the Dozen (2003)   \n",
       "6023935   74055     1222                    Full Metal Jacket (1987)   \n",
       "4471978   54819     8530                         Dear Frankie (2004)   \n",
       "9875772  121229     3114                          Toy Story 2 (1999)   \n",
       "\n",
       "                                                genre_list  \n",
       "5629735                           [Comedy, Drama, Fantasy]  \n",
       "860377   [Action, Adventure, Comedy, Fantasy, Horror, T...  \n",
       "9754589            [Animation, Children, Fantasy, Musical]  \n",
       "4315380                                     [Crime, Drama]  \n",
       "2316268                                    [Comedy, Crime]  \n",
       "...                                                    ...  \n",
       "7305429                           [Action, Comedy, Sci-Fi]  \n",
       "5689997                                 [Children, Comedy]  \n",
       "6023935                                       [Drama, War]  \n",
       "4471978                                   [Drama, Romance]  \n",
       "9875772  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
       "\n",
       "[2255305 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movie_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK0GMu3qzn6P"
   },
   "source": [
    "### Obtención de Top K Categorías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "m90169imu7Rc"
   },
   "outputs": [],
   "source": [
    "user_genre_counts_test = {}\n",
    "\n",
    "for index, row in data_movie_test.iterrows():\n",
    "    user_id = row['userId']\n",
    "    genres = row['genre_list']\n",
    "\n",
    "    if user_id not in user_genre_counts_test:\n",
    "        user_genre_counts_test[user_id] = {}\n",
    "\n",
    "    for genre in genres:\n",
    "      if genre not in user_genre_counts_test[user_id]:\n",
    "          user_genre_counts_test[user_id][genre] =  0\n",
    "      user_genre_counts_test[user_id][genre] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "OURJIAacvL1x"
   },
   "outputs": [],
   "source": [
    "path = \"/content/drive/MyDrive/IIC3633-2024-2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "YD3HSvUNvNhy"
   },
   "outputs": [],
   "source": [
    "#Guardar user_genre_counts_test and data_movie_train and data_movie_test\n",
    "import csv\n",
    "\n",
    "with open(path+'data_movie_train.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\n",
    "    writer.writerows(data_movie_train.values)\n",
    "\n",
    "with open(path+'data_movie_test.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\n",
    "    writer.writerows(data_movie_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqBGWtd5zRT8"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(path+'user_genre_counts_test.csv', 'w') as file:\n",
    "    json.dump(user_genre_counts_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Rgz0YncvTkz"
   },
   "outputs": [],
   "source": [
    "#Obtener user_genre_counts_test and data_movie_train and data_movie_test\n",
    "import csv\n",
    "\n",
    "with open(path+'data_movie_train.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Saltar la primera fila (encabezados)\n",
    "    data_movie_train = list(reader)\n",
    "    data_movie_train = pd.DataFrame(data_movie_train, columns=['userId', 'movieId', 'title', 'genre_list'])\n",
    "    data_movie_train['genre_list'] = data_movie_train['genre_list'].apply(lambda x: x.split(','))\n",
    "\n",
    "with open(path+'data_movie_test.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Saltar la primera fila (encabezados)\n",
    "    data_movie_test = list(reader)\n",
    "    data_movie_test = pd.DataFrame(data_movie_test, columns=['userId', 'movieId', 'title', 'genre_list'])\n",
    "    data_movie_test['genre_list'] = data_movie_test['genre_list'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(path+'user_genre_counts_test.csv', 'r') as file:\n",
    "    user_genre_counts_test = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXVjjqkyzeVZ"
   },
   "outputs": [],
   "source": [
    "def get_top_k_categories(df, k):\n",
    "  top_k_genres_data = []\n",
    "\n",
    "  # Itera sobre cada usuario en user\n",
    "  for user_id, genres in user_genre_counts_test.items():\n",
    "    # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\n",
    "    sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    for genre, _ in sorted_genres:\n",
    "      top_k_genres_data.append({\n",
    "          'userId': user_id,\n",
    "          'genre_principal': genre,\n",
    "          'count': genres[genre]\n",
    "      })\n",
    "\n",
    "\n",
    "  top_k_5_categories_total = pd.DataFrame(top_k_genres_data)\n",
    "\n",
    "  return top_k_5_categories_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ7B5xYiztSV"
   },
   "source": [
    "### Recomendación de Most Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "BI2wF-vQbvv-"
   },
   "outputs": [],
   "source": [
    "def recommend_most_popular(user, data_train, k=10):\n",
    "  # Agrugar por pelicula contando la cantidad de apariciones\n",
    "  data_movie_count = data_train.groupby('movieId')['movieId'].count().reset_index(name='popularity')\n",
    "\n",
    "  # Ordenar por popularity\n",
    "  data_movie_count = data_movie_count.sort_values('popularity', ascending=False)\n",
    "  top_k_popular_movie = data_movie_count.head(k)\n",
    "\n",
    "  top_k_popular_movie = top_k_popular_movie['movieId'].tolist()\n",
    "\n",
    "  return top_k_popular_movie\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-Rzlv7UvY_r"
   },
   "source": [
    "## Método Random\n",
    "Recomienda peliculas de manera aleatoria del conjunto de entrenamiento.\n",
    "- Selecciona `k` peliculas aleatorias\n",
    "- Usado como baseline para comparaciones\n",
    "- Debiese mostrar un aumento en la diversidad de las recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "G3X_e8PZyyoU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_random(user, data_train, k=10):\n",
    "  # Obtener todas las peliculas unicas\n",
    "  unique_movies = data_train['movieId'].unique()\n",
    "\n",
    "  # Seleccionar k peliculas aleatorias\n",
    "  random_movies = random.sample(list(unique_movies), min(k, len(unique_movies)))\n",
    "\n",
    "  return random_movies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9pOcjT_vgFs"
   },
   "source": [
    "## Método IKNN\n",
    " Recomienda películas usando filtrado colaborativo basado en usuarios (IKNN - Item K-Nearest Neighbors).\n",
    "\n",
    " - Calcula la similitud entre usuarios basada en las películas que han visto\n",
    " - Usa `similitud coseno` para encontrar los k usuarios más similares\n",
    " - Recomienda películas que los usuarios similares han visto pero el usuario actual no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "VWGNdIiF0H65"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class MovieIKNN:\n",
    "    def __init__(self, k=20):\n",
    "        self.k = k\n",
    "        self.item_similarity = None\n",
    "        self.item_ids = None\n",
    "        self.user_ids = None\n",
    "        \n",
    "    def _create_user_item_matrix(self, df):\n",
    "        \"\"\"\n",
    "        Crea matriz usuario-item a partir del dataframe\n",
    "        \"\"\"\n",
    "        # Crear mapeos de IDs únicos\n",
    "        unique_users = df['userId'].unique()\n",
    "        unique_items = df['movieId'].unique()\n",
    "        self.user_ids = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.item_ids = {item: idx for idx, item in enumerate(unique_items)}\n",
    "        \n",
    "        # Crear matriz de interacciones\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            user_idx = self.user_ids[row['userId']]\n",
    "            item_idx = self.item_ids[row['movieId']]\n",
    "            rows.append(user_idx)\n",
    "            cols.append(item_idx)\n",
    "            data.append(1)  # 1 para indicar interacción\n",
    "            \n",
    "        return csr_matrix((data, (rows, cols)), \n",
    "                         shape=(len(unique_users), len(unique_items)))\n",
    "    \n",
    "    def fit(self, df):\n",
    "        \"\"\"\n",
    "        Entrena el modelo con el dataframe de interacciones\n",
    "        \"\"\"\n",
    "        # Crear matriz usuario-item\n",
    "        self.user_item_matrix = self._create_user_item_matrix(df)\n",
    "        \n",
    "        # Calcular similitud entre items\n",
    "        self.item_similarity = cosine_similarity(self.user_item_matrix.T)\n",
    "        # Evitar que la similitud consigo mismo sea 1\n",
    "        np.fill_diagonal(self.item_similarity, 0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def recommend(self, username, df, n_recommendations=10):\n",
    "        \"\"\"\n",
    "        Genera recomendaciones para un usuario\n",
    "        \"\"\"\n",
    "        if username not in self.user_ids:\n",
    "            print(f\"Usuario {username} no encontrado en el dataset\")\n",
    "            return []\n",
    "        \n",
    "        # Obtener índice del usuario\n",
    "        user_idx = self.user_ids[username]\n",
    "        \n",
    "        # Obtener vector de interacciones del usuario\n",
    "        user_vector = self.user_item_matrix[user_idx].toarray().flatten()\n",
    "        \n",
    "        # Calcular predicciones\n",
    "        predictions = self._predict(user_vector)\n",
    "        \n",
    "        # Poner -inf en items ya escuchados\n",
    "        predictions[user_vector > 0] = float('-inf')\n",
    "        \n",
    "        # Obtener top N recomendaciones\n",
    "        top_idx = np.argsort(predictions)[::-1][:n_recommendations]\n",
    "        \n",
    "        # Convertir índices a nombres de canciones\n",
    "        reverse_item_ids = {v: k for k, v in self.item_ids.items()}\n",
    "        recommendations = [reverse_item_ids[idx] for idx in top_idx]\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _predict(self, user_vector):\n",
    "        \"\"\"\n",
    "        Genera predicciones para un vector de usuario\n",
    "        \"\"\"\n",
    "        # Calcular predicciones usando similitud de items\n",
    "        predictions = np.dot(self.item_similarity, user_vector)\n",
    "        \n",
    "        # Normalizar predicciones\n",
    "        sim_sums = np.sum(np.abs(self.item_similarity), axis=0)\n",
    "        sim_sums[sim_sums == 0] = 1  # Evitar división por cero\n",
    "        predictions = predictions / sim_sums\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMSdxrY_viR4"
   },
   "source": [
    "## Método Híbrido\n",
    "Método híbrido que combina popularidad con similtud de géneros según parámetro `alpha`.\n",
    "\n",
    "Basado parcialmente en el [Siguiente Articulo](https://marketsy.ai/blog/hybrid-recommender-systems-beginners-guide).\n",
    "\n",
    "- `alpha`: Parámetro para balancear entre popularidad global (`1-alpha`) y preferencias de género del usuario (`alpha`)\n",
    "- Balance entre descubrimiento y relevancia de la recomendación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "zUO7PL1CARHb"
   },
   "outputs": [],
   "source": [
    "def recommend_hybrid(user, data_train, k=10, alpha=0.5):\n",
    "    # Calcular los scores de popularidad de películas\n",
    "    popularity_scores = data_train['movieId'].value_counts().to_dict()\n",
    "    max_popularity = max(popularity_scores.values())\n",
    "    normalized_popularity = {movie: count / max_popularity for movie, count in popularity_scores.items()}\n",
    "\n",
    "    # Obtener los géneros preferidos del usuario\n",
    "    user_movies = data_train[data_train['userId'] == user]\n",
    "    user_genres = defaultdict(int)\n",
    "\n",
    "    for _, row in user_movies.iterrows():\n",
    "        for genre in row['genre_list']:\n",
    "            user_genres[genre] += 1\n",
    "\n",
    "    # Normalizamos los géneros según las frecuencias de películas\n",
    "    total_user_movies = sum(user_genres.values())\n",
    "    prefered_user_genres = {genre: count / total_user_movies for genre, count in user_genres.items()}\n",
    "\n",
    "    # Calcular el score combinado híbrido\n",
    "    hybrid_scores = {}\n",
    "    for _, row in data_train.iterrows():\n",
    "        movie = row['movieId']\n",
    "        genres = row['genre_list']\n",
    "\n",
    "        # Score de popularidad\n",
    "        movie_popularity = normalized_popularity.get(movie, 0)\n",
    "\n",
    "        # Score de géneros\n",
    "        genre_score = sum(prefered_user_genres.get(genre, 0) for genre in genres)\n",
    "\n",
    "        # Combinar scores de popularidad y género\n",
    "        hybrid_scores[movie] = (1 - alpha) * movie_popularity + alpha * genre_score\n",
    "\n",
    "    # Filtrar las películas ya vistas por el usuario\n",
    "    user_watched = set(user_movies['movieId'])\n",
    "    hybrid_scores = {movie: score for movie, score in hybrid_scores.items() if movie not in user_watched}\n",
    "\n",
    "    # Retornar las top k películas recomendadas\n",
    "    top_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [movie for movie, _ in top_recommendations[:k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US6Y_qaNiNfu"
   },
   "source": [
    "# Calculamos Métricas:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEPdt3u5WVXr"
   },
   "source": [
    "## Metricas de Precisión\n",
    "- MAP\n",
    "- NDCG@5\n",
    "- Precision@10\n",
    "- Recall@10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "pdzLUr2bC6dN"
   },
   "outputs": [],
   "source": [
    "def calculate_map(test_data, user_recommendation, user):\n",
    "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
    "\n",
    "  # Inicializar variables\n",
    "  precision_sum = 0\n",
    "  relevant_count = 0\n",
    "\n",
    "  for i, item in enumerate(user_recommendation, start=1):\n",
    "    if item in relevant_items:\n",
    "      relevant_count += 1\n",
    "      precision_sum += relevant_count / i\n",
    "\n",
    "  if relevant_count > 0:\n",
    "    map_value = precision_sum / relevant_count\n",
    "  else:\n",
    "    map_value = 0\n",
    "\n",
    "  return map_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "7p1J8piDERMQ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_ndcg(test_data, user_recommendation, user):\n",
    "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
    "\n",
    "  # Calcular DCG e IDCG\n",
    "  dcg = 0\n",
    "  idcg = 0\n",
    "  for i, item in enumerate(user_recommendation, start=1):\n",
    "    if item in relevant_items:\n",
    "      dcg += 1 / math.log2(i + 1)\n",
    "    idcg += 1 / math.log2(i + 1)\n",
    "\n",
    "  # Calcular NDCG\n",
    "  if idcg > 0:\n",
    "    ndcg_value = dcg / idcg\n",
    "  else:\n",
    "    ndcg_value = 0\n",
    "\n",
    "  return ndcg_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "0YV8xhO-aLPG"
   },
   "outputs": [],
   "source": [
    "def calculate_precision_at_k(test_data, user_recommendation, user):\n",
    "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
    "\n",
    "  relevant_count = 0\n",
    "  for item in user_recommendation:\n",
    "    if item in relevant_items:\n",
    "      relevant_count += 1\n",
    "\n",
    "  precision_at_k = relevant_count / len(user_recommendation)\n",
    "\n",
    "  return precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "1n6oA1mzacnn"
   },
   "outputs": [],
   "source": [
    "def calculate_recall_at_k(test_data, user_recommendation, user):\n",
    "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
    "\n",
    "  relevant_count = 0\n",
    "  for item in user_recommendation:\n",
    "    if item in relevant_items:\n",
    "      relevant_count += 1\n",
    "\n",
    "  recall_at_k = relevant_count / len(relevant_items)\n",
    "\n",
    "  return recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5c3T-7RzWcS6"
   },
   "source": [
    "\n",
    "## Métricas de Diversidad: ¡Enfoque del Estudio!\n",
    "- **User Diversity**: Métrica propuesta por la investigación\n",
    "- Long Tail\n",
    "- Shannon Entropy\n",
    "- Intra List Diversity\n",
    "- Diversity Coverage\n",
    "- Inverse Propensity Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYfcGlSqJcMK"
   },
   "source": [
    "### Definición de **USER DIVERSITY**, la métrica de la investigación.\n",
    "1. `UD = 1 - (|∑{j=1...k}[(R_j/R)*log(R_j/R)]| / log(k))`\n",
    "2. `k`: número de categorías para un usuario.\n",
    "3. `R`: número total de recomendaciones.\n",
    "4. `(R_j/R)`: Proporción de recomendaciones del usuario que pertenecen a la categoría `j`\n",
    "5. `log(...)`: para penalizar concentración excesiva en una sola categoría.\n",
    "6. `/ log(k)`: normaliza el valor.\n",
    "7. `1 - `: Valor resultante entre 0 y 1.\n",
    "8. *Valor alto*: alta diversidad en las recomendaciones recibidas por el usuario (pertenecen a varias categorías favoritas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "GFRa6xoowmqk"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_user_diversity(user_top_categories, user_recommendation, user_id, k=5):\n",
    "    # Obtener las top k categorías del usuario\n",
    "    categories_user = user_top_categories[user_top_categories['userId'] == user_id]['genre_principal'].tolist()[:k]\n",
    "\n",
    "    # Filtrar recomendaciones para géneros relevantes\n",
    "    filtered_recommendations = []\n",
    "    for rec in user_recommendation:\n",
    "      genre_list = movies.copy()\n",
    "      genre_list = genre_list[genre_list['movieId'] == rec]\n",
    "      genre_list['genres_list'] = genre_list['genres'].str.split('|')\n",
    "      genre_list = genre_list['genres_list'].tolist()\n",
    "      genre_list_total = []\n",
    "      for genre in genre_list:\n",
    "        genre_list_total.extend(genre)\n",
    "      if rec in genre_list_total:\n",
    "        filtered_recommendations.append(rec)\n",
    "\n",
    "\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(filtered_recommendations)\n",
    "    if r == 0:\n",
    "        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\n",
    "\n",
    "    # Filtrar datos de movie para las peliculas recomendadas relevantes\n",
    "    filtered_data = data_movie[data_movie['movieId'].isin(filtered_recommendations)]\n",
    "\n",
    "    # Calcular sum_diversity\n",
    "    sum_diversity = 0\n",
    "    for genre in categories_user:\n",
    "        recommended_movie_genre = filtered_data[filtered_data['genre_list'].apply(lambda x: genre in x)]['movieId'].tolist()\n",
    "        r_j = len(recommended_movie_genre)\n",
    "\n",
    "        if r_j > 0:\n",
    "            proportion = r_j / r\n",
    "            contribution = proportion * math.log(proportion)\n",
    "            sum_diversity += contribution\n",
    "\n",
    "    # Normalizar con log(k)\n",
    "    max_diversity = math.log(k) if k > 1 else 1.0\n",
    "    # Ponemos en valor absoluto sum_diversity\n",
    "    sum_diversity = abs(sum_diversity)\n",
    "\n",
    "    if max_diversity == 0:\n",
    "        return 0.0  # Si k <= 1, diversidad no tiene sentido\n",
    "\n",
    "    # Calcular diversidad final\n",
    "    diversity = 1 - (sum_diversity / max_diversity)\n",
    "\n",
    "    # Depuración adicional\n",
    "    return diversity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZEaHnChqo0j"
   },
   "source": [
    "### **Long Tail**:\n",
    "Mide que tan diversas son las recomendaciones en términos de popularidad de los items.\n",
    "1.  Equación: `LT = |Intersection(Rec, TailItems)| / |Rec|`\n",
    "2. Parametro `beta=0.4`: define umbral para considerar item como parte de la cola larga.\n",
    "3. *Valor alto*: se recomiendan más items poco populares\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "JSxWcIUbJ1Ux"
   },
   "outputs": [],
   "source": [
    "def calculate_long_tail(test_data, user_recommendation, user_id, beta_value=0.5):\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(user_recommendation)\n",
    "    if r == 0:\n",
    "        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\n",
    "\n",
    "    # Procesamos las recomendaciones para obtener la popularidad de los items:\n",
    "    item_popularity = test_data['movieId'].value_counts().to_dict()\n",
    "\n",
    "    # Ordenamos los items por popularidad\n",
    "    sorted_items = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
    "    n_items = len(sorted_items)\n",
    "    tail_max = int(beta_value * n_items)\n",
    "\n",
    "    # Identificamos los items en la LT\n",
    "    long_tail = set(item for item, _ in sorted_items[tail_max:])\n",
    "\n",
    "    # Calculamos la proporcion de items recomendades nen la cola larga\n",
    "    longtail_recommendation = sum(1 for item in user_recommendation if item in long_tail)\n",
    "\n",
    "    return longtail_recommendation / r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmJOSk-xqs_J"
   },
   "source": [
    "### **Entropía de Shannon**:\n",
    "Mide la incertidumbre o aleatoriedad de la distribución de recomendaciones.\n",
    "1. `H = -∑(pi*log2(pi)) / log2(n)`\n",
    "2. `pi`: probabilidad de cada item en las recomendaciones\n",
    "3. *Valor alto*: mayor aleatoriedad/diversidad en las recomendaciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "tugWz76tKi9-"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_shannon_entropy(test_data, user_recommendation, user_id):\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(user_recommendation)\n",
    "    if r == 0:\n",
    "        return 0.0  # Si no hay recomendaciones, entropía es 0.\n",
    "\n",
    "    # Obtener géneros de las películas recomendadas\n",
    "    rec_genres = []\n",
    "    for rec in user_recommendation:\n",
    "        movie_genres = test_data[test_data['movieId'] == rec]['genre_list']\n",
    "        if not movie_genres.empty:\n",
    "            rec_genres.extend(movie_genres.iloc[0])  # Añadir los géneros de la película\n",
    "\n",
    "    # Si no hay géneros recomendados, devolver 0\n",
    "    if len(rec_genres) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Contar la frecuencia de cada género\n",
    "    genre_counts = {genre: rec_genres.count(genre) for genre in set(rec_genres)}\n",
    "    frequencies = [count / r for count in genre_counts.values()]\n",
    "\n",
    "    # Calcular la entropía\n",
    "    entropy = -sum(p * math.log(p, 2) for p in frequencies if p > 0)\n",
    "\n",
    "    # Normalizar con log(r)\n",
    "    max_entropy = math.log(r, 2) if r > 1 else 1.0\n",
    "    entropy /= max_entropy\n",
    "\n",
    "    return entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9KGJFp8qwYp"
   },
   "source": [
    "### **Intra List Diversity**:\n",
    "Calcula diversidad basándose en la similitud entre los items.\n",
    "1. `ILD = ∑∑(d(i,j)) / (n*(n-1)/2)`\n",
    "2. `d(i,j)`: es la distancia entre los items `i` y `j`, usando coseno\n",
    "3. *Valor alto*: mayor diversidad entre los items recomendados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "WVFAJiK5K58R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_intra_list_diversity(test_data, user_recommendation, user_id):\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(user_recommendation)\n",
    "    if r < 2:\n",
    "        return 0.0  # Diversidad no se puede calcular con menos de 2 recomendaciones\n",
    "\n",
    "    # Crear one-hot encoding de características basadas en géneros\n",
    "    unique_genres = set(genre for genres in test_data['genre_list'] for genre in genres)\n",
    "    genre_to_index = {genre: idx for idx, genre in enumerate(unique_genres)}\n",
    "\n",
    "    # Crear vectores one-hot para cada película recomendada\n",
    "    genre_vectors = []\n",
    "    for movie_id in user_recommendation:\n",
    "        movie_data = test_data[test_data['movieId'] == movie_id]\n",
    "        if not movie_data.empty:\n",
    "            genres = movie_data.iloc[0]['genre_list']\n",
    "            one_hot = [1 if genre_to_index[genre] in [genre_to_index[g] for g in genres] else 0\n",
    "                       for genre in unique_genres]\n",
    "            genre_vectors.append(one_hot)\n",
    "\n",
    "    # Si no hay recomendaciones relevantes, devolver 0\n",
    "    if len(genre_vectors) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    # Convertir los vectores a una matriz\n",
    "    feature_vectors = np.array(genre_vectors)\n",
    "\n",
    "    # Calcular matriz de similitud usando producto punto\n",
    "    similarity_matrix = np.dot(feature_vectors, feature_vectors.T)\n",
    "    n = len(feature_vectors)\n",
    "\n",
    "    # Calcular la diversidad intra-lista como la distancia coseno promedio\n",
    "    total_similarity = np.sum(similarity_matrix) - np.sum(np.diag(similarity_matrix))\n",
    "    comparisons = n * (n - 1)  # Total de pares únicos\n",
    "    intra_list_diversity = 1 - (total_similarity / comparisons)\n",
    "\n",
    "    return intra_list_diversity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deRuDWKOq0yr"
   },
   "source": [
    "### **Diversity Coverage**:\n",
    "Mide la cobertura como la proporción de items únicos recomendados respceto al total de items posibles.\n",
    "1. `DC = |Unique_Rec| / |All Items|`\n",
    "2. *Valor alto*: se están recomendando items de todo el catálogo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "FwVhP8vNLGPb"
   },
   "outputs": [],
   "source": [
    "def calculate_diversity_coverage(test_data, user_recommendation, user_id):\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(user_recommendation)\n",
    "    if r == 0:\n",
    "        return 0.0  # Si no hay recomendaciones, cobertura es 0.\n",
    "\n",
    "    # Obtener géneros únicos de las películas recomendadas\n",
    "    rec_genres = set()\n",
    "    for rec in user_recommendation:\n",
    "        movie_data = test_data[test_data['movieId'] == rec]\n",
    "        if not movie_data.empty:\n",
    "            rec_genres.update(movie_data.iloc[0]['genre_list'])\n",
    "\n",
    "    # Si no hay géneros recomendados, devolver 0\n",
    "    if len(rec_genres) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Obtener todos los posibles géneros\n",
    "    all_genres = set(genre for genres in test_data['genre_list'] for genre in genres)\n",
    "\n",
    "    # Calcular la cobertura de la diversidad\n",
    "    diversity_coverage = len(rec_genres) / len(all_genres)\n",
    "\n",
    "    return diversity_coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuETWeMJq3NL"
   },
   "source": [
    "### **Inverse Propensity Score** (IPS):\n",
    "Penaliza la recomendación de items muy populares\n",
    "1. `IPS = (1/p(i))`\n",
    "2. Parametro `lambda` para suavizar la propensidad\n",
    "3. `p(i)`: probabilidad que el item `i` sea seleccionado\n",
    "4. *Valor alto*: se están recomendando más items poco probables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "3Ec92UgBXkMX"
   },
   "outputs": [],
   "source": [
    "def calculate_inverse_propensity_score(test_data, user_recommendation, user_id, lambda_value=0.5):\n",
    "    # Total de recomendaciones relevantes\n",
    "    r = len(user_recommendation)\n",
    "    if r == 0:\n",
    "        return 0.0  # Si no hay recomendaciones, el IPS es 0.\n",
    "\n",
    "    # Calcular la popularidad de las películas\n",
    "    movie_popularity = test_data['movieId'].value_counts().to_dict()\n",
    "    interaction_count = sum(movie_popularity.values())\n",
    "\n",
    "    # Calcular Propensity Score\n",
    "    prop_score = {\n",
    "        movie: ((movie_popularity.get(movie, 0) + lambda_value) / (interaction_count + lambda_value))\n",
    "        for movie in test_data['movieId'].unique()\n",
    "    }\n",
    "\n",
    "    # Calcular el IPS promedio\n",
    "    ips = [1 / prop_score[movie] for movie in user_recommendation if movie in prop_score]\n",
    "    if len(ips) > 0:\n",
    "        ips_avg = sum(ips) / len(ips)\n",
    "        return ips_avg\n",
    "    else:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqwU42k6icty"
   },
   "source": [
    "# Ejecución Método Most Popular. PROBAR: Random y Collaborative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLh-GFiMwFMB"
   },
   "source": [
    "Creamos una función para ejecutar el modelo con parametros modificables correspondientes a:\n",
    "- `test_data`: Datos para testeo del modelo\n",
    "- `train_data`: Datos para entrenamiento del modelo\n",
    "- `top_n`: Para recommendación *Most Popular*\n",
    "- `k`: Cuantos clusters de géneros se considerarán para los usuarios\n",
    "- `beta_lt`: Parametro beta de métrica *Long Tail*, define umbral para considerar un item como parte de la *Long Tail*\n",
    "- `lambda_ips`: Parámetro de métrica *Inverse Propensity Score*, sirve para suavizar el resultado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "fvZHOLECFVhb"
   },
   "outputs": [],
   "source": [
    "def most_popular_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
    "  map_sum = 0\n",
    "  ndcg_sum = 0\n",
    "  precision_sum = 0\n",
    "  recall_sum = 0\n",
    "  diversity_sum = 0\n",
    "  lt_sum = 0\n",
    "  entropy_sum = 0\n",
    "  ild_sum = 0\n",
    "  dc_sum = 0\n",
    "  ips_sum = 0\n",
    "  user_count = 0\n",
    "\n",
    "\n",
    "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
    "\n",
    "  for userid in test_data['userId'].unique():\n",
    "\n",
    "    recommend_list = recommend_most_popular(userid, train_data, top_n)\n",
    "\n",
    "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
    "\n",
    "    # Calcular Map y nDCG y User Diversity\n",
    "    map_user = calculate_map(test_data, recommend_list, userid)\n",
    "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
    "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
    "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
    "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
    "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
    "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
    "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
    "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
    "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
    "\n",
    "    map_sum += map_user\n",
    "    ndcg_sum += ndcg_user\n",
    "    precision_sum += precision_user\n",
    "    recall_sum += recall_user\n",
    "    diversity_sum += diversity_user\n",
    "    lt_sum += lt_user\n",
    "    entropy_sum += entropy_user\n",
    "    ild_sum += ild_user\n",
    "    dc_sum += dc_user\n",
    "    ips_sum += ips_user\n",
    "    user_count += 1\n",
    "\n",
    "  # Promedio de métricas\n",
    "  map_avg = map_sum / user_count\n",
    "  ndcg_avg = ndcg_sum / user_count\n",
    "  precision_avg = precision_sum / user_count\n",
    "  recall_avg = recall_sum / user_count\n",
    "  diversity_avg = diversity_sum / user_count\n",
    "  lt_avg = lt_sum / user_count\n",
    "  entropy_avg = entropy_sum / user_count\n",
    "  ild_avg = ild_sum / user_count\n",
    "  dc_avg = dc_sum / user_count\n",
    "  ips_avg = ips_sum / user_count\n",
    "\n",
    "  return {\n",
    "      \"MAP\": map_avg,\n",
    "      \"nDCG\": ndcg_avg,\n",
    "      \"Precision\": precision_avg,\n",
    "      \"Recall\": recall_avg,\n",
    "      \"User_Diversity\": diversity_avg,\n",
    "      \"Long_Tail\": lt_avg,\n",
    "      \"Shannon_Entropy\": entropy_avg,\n",
    "      \"Intra_List_Diversity\": ild_avg,\n",
    "      \"Diversity_Coverage\": dc_avg,\n",
    "      \"Inverse_Propensity_Score\": ips_avg\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wHcux_JRJjE"
   },
   "source": [
    "# Ejecución Método Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "wFyUHSuVRJTu"
   },
   "outputs": [],
   "source": [
    "def random_metrcis(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
    "  map_sum = 0\n",
    "  ndcg_sum = 0\n",
    "  precision_sum = 0\n",
    "  recall_sum = 0\n",
    "  diversity_sum = 0\n",
    "  lt_sum = 0\n",
    "  entropy_sum = 0\n",
    "  ild_sum = 0\n",
    "  dc_sum = 0\n",
    "  ips_sum = 0\n",
    "  user_count = 0\n",
    "\n",
    "\n",
    "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
    "\n",
    "  for userid in test_data['userId'].unique():\n",
    "\n",
    "    recommend_list = recommend_random(userid, train_data, top_n)\n",
    "\n",
    "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
    "\n",
    "    # Calcular Map y nDCG y User Diversity\n",
    "    map_user = calculate_map(test_data, recommend_list, userid)\n",
    "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
    "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
    "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
    "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
    "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
    "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
    "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
    "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
    "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
    "\n",
    "    map_sum += map_user\n",
    "    ndcg_sum += ndcg_user\n",
    "    precision_sum += precision_user\n",
    "    recall_sum += recall_user\n",
    "    diversity_sum += diversity_user\n",
    "    lt_sum += lt_user\n",
    "    entropy_sum += entropy_user\n",
    "    ild_sum += ild_user\n",
    "    dc_sum += dc_user\n",
    "    ips_sum += ips_user\n",
    "    user_count += 1\n",
    "\n",
    "  # Promedio de métricas\n",
    "  map_avg = map_sum / user_count\n",
    "  ndcg_avg = ndcg_sum / user_count\n",
    "  precision_avg = precision_sum / user_count\n",
    "  recall_avg = recall_sum / user_count\n",
    "  diversity_avg = diversity_sum / user_count\n",
    "  lt_avg = lt_sum / user_count\n",
    "  entropy_avg = entropy_sum / user_count\n",
    "  ild_avg = ild_sum / user_count\n",
    "  dc_avg = dc_sum / user_count\n",
    "  ips_avg = ips_sum / user_count\n",
    "\n",
    "  return {\n",
    "      \"MAP\": map_avg,\n",
    "      \"nDCG\": ndcg_avg,\n",
    "      \"Precision\": precision_avg,\n",
    "      \"Recall\": recall_avg,\n",
    "      \"User_Diversity\": diversity_avg,\n",
    "      \"Long_Tail\": lt_avg,\n",
    "      \"Shannon_Entropy\": entropy_avg,\n",
    "      \"Intra_List_Diversity\": ild_avg,\n",
    "      \"Diversity_Coverage\": dc_avg,\n",
    "      \"Inverse_Propensity_Score\": ips_avg\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIv6m1ndTAt3"
   },
   "source": [
    "# Ejecución de método IKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "nNyNGhqmTGT6"
   },
   "outputs": [],
   "source": [
    "def IKNN_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
    "  map_sum = 0\n",
    "  ndcg_sum = 0\n",
    "  precision_sum = 0\n",
    "  recall_sum = 0\n",
    "  diversity_sum = 0\n",
    "  lt_sum = 0\n",
    "  entropy_sum = 0\n",
    "  ild_sum = 0\n",
    "  dc_sum = 0\n",
    "  ips_sum = 0\n",
    "  user_count = 0\n",
    "\n",
    "\n",
    "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
    "\n",
    "  for userid in test_data['userId'].unique():\n",
    "    model = MovieIKNN(k=20)\n",
    "    model.fit(train_data)\n",
    "\n",
    "    recommend_list = model.recommend(userid, train_data, top_n)\n",
    "\n",
    "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
    "\n",
    "    # Calcular Map y nDCG y User Diversity\n",
    "    map_user = calculate_map(test_data, recommend_list, userid)\n",
    "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
    "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
    "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
    "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
    "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
    "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
    "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
    "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
    "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
    "\n",
    "    map_sum += map_user\n",
    "    ndcg_sum += ndcg_user\n",
    "    precision_sum += precision_user\n",
    "    recall_sum += recall_user\n",
    "    diversity_sum += diversity_user\n",
    "    lt_sum += lt_user\n",
    "    entropy_sum += entropy_user\n",
    "    ild_sum += ild_user\n",
    "    dc_sum += dc_user\n",
    "    ips_sum += ips_user\n",
    "    user_count += 1\n",
    "\n",
    "  # Promedio de métricas\n",
    "  map_avg = map_sum / user_count\n",
    "  ndcg_avg = ndcg_sum / user_count\n",
    "  precision_avg = precision_sum / user_count\n",
    "  recall_avg = recall_sum / user_count\n",
    "  diversity_avg = diversity_sum / user_count\n",
    "  lt_avg = lt_sum / user_count\n",
    "  entropy_avg = entropy_sum / user_count\n",
    "  ild_avg = ild_sum / user_count\n",
    "  dc_avg = dc_sum / user_count\n",
    "  ips_avg = ips_sum / user_count\n",
    "\n",
    "  return {\n",
    "      \"MAP\": map_avg,\n",
    "      \"nDCG\": ndcg_avg,\n",
    "      \"Precision\": precision_avg,\n",
    "      \"Recall\": recall_avg,\n",
    "      \"User_Diversity\": diversity_avg,\n",
    "      \"Long_Tail\": lt_avg,\n",
    "      \"Shannon_Entropy\": entropy_avg,\n",
    "      \"Intra_List_Diversity\": ild_avg,\n",
    "      \"Diversity_Coverage\": dc_avg,\n",
    "      \"Inverse_Propensity_Score\": ips_avg\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4j9JMlI1Won2"
   },
   "source": [
    "# Ejecución de método hibrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "weIgdZN-YQkK"
   },
   "outputs": [],
   "source": [
    "def hybrid_metrics(test_data, train_data, top_n, k, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5):\n",
    "  map_sum = 0\n",
    "  ndcg_sum = 0\n",
    "  precision_sum = 0\n",
    "  recall_sum = 0\n",
    "  diversity_sum = 0\n",
    "  lt_sum = 0\n",
    "  entropy_sum = 0\n",
    "  ild_sum = 0\n",
    "  dc_sum = 0\n",
    "  ips_sum = 0\n",
    "  user_count = 0\n",
    "\n",
    "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
    "\n",
    "  for userid in test_data['userId'].unique():\n",
    "\n",
    "    recommend_list = recommend_hybrid(userid, train_data, top_n, alpha_hybrid)\n",
    "\n",
    "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
    "\n",
    "    # Calcular Map y nDCG y User Diversity\n",
    "    map_user = calculate_map(test_data, recommend_list, userid)\n",
    "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
    "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
    "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
    "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
    "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
    "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
    "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
    "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
    "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
    "\n",
    "    map_sum += map_user\n",
    "    ndcg_sum += ndcg_user\n",
    "    precision_sum += precision_user\n",
    "    recall_sum += recall_user\n",
    "    diversity_sum += diversity_user\n",
    "    lt_sum += lt_user\n",
    "    entropy_sum += entropy_user\n",
    "    ild_sum += ild_user\n",
    "    dc_sum += dc_user\n",
    "    ips_sum += ips_user\n",
    "    user_count += 1\n",
    "\n",
    "  # Promedio de métricas\n",
    "  map_avg = map_sum / user_count\n",
    "  ndcg_avg = ndcg_sum / user_count\n",
    "  precision_avg = precision_sum / user_count\n",
    "  recall_avg = recall_sum / user_count\n",
    "  diversity_avg = diversity_sum / user_count\n",
    "  lt_avg = lt_sum / user_count\n",
    "  entropy_avg = entropy_sum / user_count\n",
    "  ild_avg = ild_sum / user_count\n",
    "  dc_avg = dc_sum / user_count\n",
    "  ips_avg = ips_sum / user_count\n",
    "\n",
    "  return {\n",
    "      \"MAP\": map_avg,\n",
    "      \"nDCG\": ndcg_avg,\n",
    "      \"Precision\": precision_avg,\n",
    "      \"Recall\": recall_avg,\n",
    "      \"User_Diversity\": diversity_avg,\n",
    "      \"Long_Tail\": lt_avg,\n",
    "      \"Shannon_Entropy\": entropy_avg,\n",
    "      \"Intra_List_Diversity\": ild_avg,\n",
    "      \"Diversity_Coverage\": dc_avg,\n",
    "      \"Inverse_Propensity_Score\": ips_avg\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg-8ejrrx2Ih"
   },
   "source": [
    "## Ejecución y obtención de métricas\n",
    "\n",
    "### Metodo Most Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "id": "t_lsMr2BGx2D"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metric_results \u001b[38;5;241m=\u001b[39m \u001b[43mmost_popular_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_movie_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_movie_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_lt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_ips\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnDCG: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnDCG\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[62], line 32\u001b[0m, in \u001b[0;36mmost_popular_metrics\u001b[0;34m(test_data, train_data, top_n, k, beta_lt, lambda_ips)\u001b[0m\n\u001b[1;32m     30\u001b[0m entropy_user \u001b[38;5;241m=\u001b[39m calculate_shannon_entropy(test_data, recommend_list, userid)\n\u001b[1;32m     31\u001b[0m ild_user \u001b[38;5;241m=\u001b[39m calculate_intra_list_diversity(test_data, recommend_list, userid)\n\u001b[0;32m---> 32\u001b[0m dc_user \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_diversity_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommend_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m ips_user \u001b[38;5;241m=\u001b[39m calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n\u001b[1;32m     35\u001b[0m map_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m map_user\n",
      "Cell \u001b[0;32mIn[60], line 19\u001b[0m, in \u001b[0;36mcalculate_diversity_coverage\u001b[0;34m(test_data, user_recommendation, user_id)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Obtener todos los posibles géneros\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m all_genres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenre_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenre\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calcular la cobertura de la diversidad\u001b[39;00m\n\u001b[1;32m     22\u001b[0m diversity_coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rec_genres) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_genres)\n",
      "Cell \u001b[0;32mIn[60], line 19\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Obtener todos los posibles géneros\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m all_genres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(genre \u001b[38;5;28;01mfor\u001b[39;00m genres \u001b[38;5;129;01min\u001b[39;00m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenre_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m genres)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Calcular la cobertura de la diversidad\u001b[39;00m\n\u001b[1;32m     22\u001b[0m diversity_coverage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(rec_genres) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_genres)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric_results = most_popular_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
    "print(f\"MAP: {metric_results['MAP']}\")\n",
    "print(f\"nDCG: {metric_results['nDCG']}\")\n",
    "print(f\"Precision: {metric_results['Precision']}\")\n",
    "print(f\"Recall: {metric_results['Recall']}\")\n",
    "print(f\"User_Diversity: {metric_results['User_Diversity']}\")\n",
    "print(f\"Long_Tail: {metric_results['Long_Tail']}\")\n",
    "print(f\"Shannon_Entropy: {metric_results['Shannon_Entropy']}\")\n",
    "print(f\"Intra_List_Diversity: {metric_results['Intra_List_Diversity']}\")\n",
    "print(f\"Diversity_Coverage: {metric_results['Diversity_Coverage']}\")\n",
    "print(f\"Inverse_Propensity_Score: {metric_results['Inverse_Propensity_Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s55XJxjlRxIJ"
   },
   "source": [
    "### Método Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QjJPRu_rRu-Y"
   },
   "outputs": [],
   "source": [
    "metric_results_random = random_metrcis(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
    "print(f\"MAP: {metric_results_random['MAP']}\")\n",
    "print(f\"nDCG: {metric_results_random['nDCG']}\")\n",
    "print(f\"Precision: {metric_results_random['Precision']}\")\n",
    "print(f\"Recall: {metric_results_random['Recall']}\")\n",
    "print(f\"User_Diversity: {metric_results_random['User_Diversity']}\")\n",
    "print(f\"Long_Tail: {metric_results_random['Long_Tail']}\")\n",
    "print(f\"Shannon_Entropy: {metric_results_random['Shannon_Entropy']}\")\n",
    "print(f\"Intra_List_Diversity: {metric_results_random['Intra_List_Diversity']}\")\n",
    "print(f\"Diversity_Coverage: {metric_results_random['Diversity_Coverage']}\")\n",
    "print(f\"Inverse_Propensity_Score: {metric_results_random['Inverse_Propensity_Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdAdycuzSr4h"
   },
   "source": [
    "Método IKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "W5zSjSBoSqPm"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'genre_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Code/Recomendadores/IIC3633_ProyectoMetricaDiversidad/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'genre_list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metric_results_iknn \u001b[38;5;241m=\u001b[39m \u001b[43mIKNN_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_movie_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_movie_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_lt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_ips\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_results_iknn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnDCG: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_results_iknn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnDCG\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[64], line 32\u001b[0m, in \u001b[0;36mIKNN_metrics\u001b[0;34m(test_data, train_data, top_n, k, beta_lt, lambda_ips)\u001b[0m\n\u001b[1;32m     30\u001b[0m diversity_user \u001b[38;5;241m=\u001b[39m calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n\u001b[1;32m     31\u001b[0m lt_user \u001b[38;5;241m=\u001b[39m calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n\u001b[0;32m---> 32\u001b[0m entropy_user \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_shannon_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecommend_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m ild_user \u001b[38;5;241m=\u001b[39m calculate_intra_list_diversity(test_data, recommend_list, userid)\n\u001b[1;32m     34\u001b[0m dc_user \u001b[38;5;241m=\u001b[39m calculate_diversity_coverage(test_data, recommend_list, userid)\n",
      "Cell \u001b[0;32mIn[58], line 12\u001b[0m, in \u001b[0;36mcalculate_shannon_entropy\u001b[0;34m(test_data, user_recommendation, user_id)\u001b[0m\n\u001b[1;32m     10\u001b[0m rec_genres \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m user_recommendation:\n\u001b[0;32m---> 12\u001b[0m     movie_genres \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovieId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrec\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenre_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m movie_genres\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     14\u001b[0m         rec_genres\u001b[38;5;241m.\u001b[39mextend(movie_genres\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Añadir los géneros de la película\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Recomendadores/IIC3633_ProyectoMetricaDiversidad/venv/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Code/Recomendadores/IIC3633_ProyectoMetricaDiversidad/venv/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'genre_list'"
     ]
    }
   ],
   "source": [
    "metric_results_iknn = IKNN_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
    "print(f\"MAP: {metric_results_iknn['MAP']}\")\n",
    "print(f\"nDCG: {metric_results_iknn['nDCG']}\")\n",
    "print(f\"Precision: {metric_results_iknn['Precision']}\")\n",
    "print(f\"Recall: {metric_results_iknn['Recall']}\")\n",
    "print(f\"User_Diversity: {metric_results_iknn['User_Diversity']}\")\n",
    "print(f\"Long_Tail: {metric_results_iknn['Long_Tail']}\")\n",
    "print(f\"Shannon_Entropy: {metric_results_iknn['Shannon_Entropy']}\")\n",
    "print(f\"Intra_List_Diversity: {metric_results_iknn['Intra_List_Diversity']}\")\n",
    "print(f\"Diversity_Coverage: {metric_results_iknn['Diversity_Coverage']}\")\n",
    "print(f\"Inverse_Propensity_Score: {metric_results_iknn['Inverse_Propensity_Score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lrHLjXrKYsgq"
   },
   "outputs": [],
   "source": [
    "metric_results_hybrid = hybrid_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
    "print(f\"MAP: {metric_results_hybrid['MAP']}\")\n",
    "print(f\"nDCG: {metric_results_hybrid['nDCG']}\")\n",
    "print(f\"Precision: {metric_results_hybrid['Precision']}\")\n",
    "print(f\"Recall: {metric_results_hybrid['Recall']}\")\n",
    "print(f\"User_Diversity: {metric_results_hybrid['User_Diversity']}\")\n",
    "print(f\"Long_Tail: {metric_results_hybrid['Long_Tail']}\")\n",
    "print(f\"Shannon_Entropy: {metric_results_hybrid['Shannon_Entropy']}\")\n",
    "print(f\"Intra_List_Diversity: {metric_results_hybrid['Intra_List_Diversity']}\")\n",
    "print(f\"Diversity_Coverage: {metric_results_hybrid['Diversity_Coverage']}\")\n",
    "print(f\"Inverse_Propensity_Score: {metric_results_hybrid['Inverse_Propensity_Score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXG_QtaQGLBg"
   },
   "source": [
    "# Ejecución Global de Métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SLOqxW5XFtEn"
   },
   "outputs": [],
   "source": [
    "def global_metrics(test_data, train_data, top_n, k, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5):\n",
    "  model_iknn = MovieIKNN(k=20)\n",
    "  model_iknn.fit(train_data)\n",
    "\n",
    "  # Arreglo para almacenar los resultados de cada metodo\n",
    "  records = []\n",
    "\n",
    "  # Obtenemos las top k categorias\n",
    "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
    "\n",
    "  for userid in test_data['user_id'].unique():\n",
    "    # Genero recomendaciones para cada modelo\n",
    "    recommendations = {\n",
    "        'most_popular': recommend_most_popular(userid, train_data, top_n),\n",
    "        'random': recommend_random(userid, train_data, top_n),\n",
    "        'iknn': model_iknn.recommend(userid, train_data, top_n),\n",
    "        'hybrid': recommend_hybrid(userid, train_data, top_n, alpha_hybrid),\n",
    "    }\n",
    "\n",
    "    # Calcular Metricas para cada modelo\n",
    "    for model, recommend_list in recommendations.items():\n",
    "      record = {\n",
    "        'user_id': userid,\n",
    "        'model': model,\n",
    "          # Metricas de precision\n",
    "        'MAP': calculate_map(test_data, recommend_list, userid),\n",
    "        'nDCG': calculate_ndcg(test_data, recommend_list, userid),\n",
    "        'Precision': calculate_precision_at_k(test_data, recommend_list, userid),\n",
    "        'Recall': calculate_recall_at_k(test_data, recommend_list, userid),\n",
    "          # Metricas de diversidad\n",
    "        'User_Diversity': calculate_user_diversity(top_k_categories_data, recommend_list, userid),\n",
    "        'Long_Tail': calculate_long_tail(test_data, recommend_list, userid, beta_lt),\n",
    "        'Shannon_Entropy': calculate_shannon_entropy(test_data, recommend_list, userid),\n",
    "        'Intra_List_Diversity': calculate_intra_list_diversity(test_data, recommend_list, userid),\n",
    "        'Diversity_Coverage': calculate_diversity_coverage(test_data, recommend_list, userid),\n",
    "        'Inverse_Propensity_Score': calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
    "      }\n",
    "      records.append(record)\n",
    "\n",
    "  # Promedio de métricas\n",
    "  results_df = pd.DataFrame(records)\n",
    "  #print(results_df.head())\n",
    "\n",
    "  return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I7-QL9RlFOA"
   },
   "outputs": [],
   "source": [
    "results_df = global_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV6yMeEWJTnz"
   },
   "source": [
    "## Analisis Global de Metricas\n",
    "Analiza y visualiza los resultados de las métricas globales usando el Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s60mg3IVLBaz"
   },
   "source": [
    "### Generar visualizaciones comparativas entre los modelos\n",
    "Creamos 3 tipos de gráficos para las visualizaciones:\n",
    "1. Gráfico de cajas para cada métrica mostrando su distribución.\n",
    "2. Heatmap de correlaciones entre métricas.\n",
    "3. Gráfico de radar para comparar modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vUA1EbSK0UL"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_global_metrics(results_df):\n",
    "  metrics = ['MAP', 'nDCG', 'Precision', 'Recall' , 'User_Diversity', 'Long_Tail', 'Shannon_Entropy', 'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
    "\n",
    "  # Configurar el estilo usando seaborn\n",
    "  sns.set_style\n",
    "\n",
    "  # Crear el gráfico de cajas para cada metrica\n",
    "  fig, axes = plt.subplots(3, 4, figsize=(20, 10))\n",
    "  fig.suptitle('Distribución de Métricas por Modelo', fontsize=16)\n",
    "\n",
    "  for i, metric in enumerate(metrics):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "    sns.boxplot(x='model', y=metric, data=results_df, ax=axes[row, col])\n",
    "    axes[row, col].set_xticklabels(axes[row, col].get_xticklabels(), rotation=45)\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel('Modelo')\n",
    "    ax.set_ylabel(metric)\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  # Generar heatmap de correlaciones entre métricas\n",
    "  correlation_matrix = results_df[metrics].corr()\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "  plt.title('Correlación entre Métricas')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  # Grafico de radar para comparar modelos\n",
    "    # Calcular promedios de las metricas normalizados\n",
    "  avg_metrics = results_df.groupby('model')[metrics].mean()\n",
    "  normalized_metrics = (avg_metrics - avg_metrics.min()) / (avg_metrics.max() - avg_metrics.min())\n",
    "\n",
    "    # Configuramos grafico de radar: https://plotly.com/python/radar-chart/\n",
    "  fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
    "  angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)\n",
    "  angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "    # Graficamos las metricas\n",
    "  for model in normalized_metrics.index:\n",
    "    values = np.concatenate((normalized_metrics.loc[model], [normalized_metrics.loc[model][0]]))\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=model)\n",
    "    ax.fill(angles, values, alpha=0.25)\n",
    "\n",
    "    # Configuramos etiquetas\n",
    "  ax.set_xticks(angles[:-1], metrics)\n",
    "  ax.set_ylim(0, 1)\n",
    "  plt.legend(loc='best', bbox_to_anchor=(0.5, -0.05))\n",
    "  plt.title('Comparación de Métodos según Métricas Normalizadas')\n",
    "  # plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LKEERnLFOiKx"
   },
   "source": [
    "### Generar Análisis Estadístico de Significancia\n",
    "Realiza un análisis estadístico de las diferencias entre modelos, incluyendo:\n",
    "1. Media y desviación estándar por modelo.\n",
    "2. Test ANOVA para evaluar la significancia estadística\n",
    "3. Correlaciones entre las métricas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKD6N9-KO6ZR"
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def analyze_significance(results_df):\n",
    "  metrics = ['MAP', 'nDCG', 'Precision', 'Recall', 'User_Diversity', 'Long_Tail', 'Shannon_Entropy', 'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
    "  # Calcular promedios de las metricas\n",
    "  avg_metrics = results_df.groupby('model').mean()\n",
    "  print(\"Promedios de Métricas por modelo:\")\n",
    "  print(avg_metrics.round(4))\n",
    "\n",
    "  # Calcular desviaciones estandar\n",
    "  std_metrics = results_df.groupby('model').std()\n",
    "  print(\"Desviaciones estandar de Métricas por modelo:\")\n",
    "  print(std_metrics.round(4))\n",
    "\n",
    "  # Calcular Test de ANOVA\n",
    "  # Generamos grupos de comparacion segun modelos\n",
    "  anova_results = {}\n",
    "  for metric in metrics:\n",
    "    groups = [group for _, group in results_df.groupby('model')[metric]]\n",
    "    f_value, p_value = stats.f_oneway(*groups)\n",
    "    anova_results[metric] = {'Estadistico-F': f_value, 'Valor-P': p_value}\n",
    "\n",
    "  # Creo un dataframe con los resultados\n",
    "  anova_df = pd.DataFrame(anova_results).T\n",
    "  print(\"Resultados ANOVA:\")\n",
    "  print(anova_df.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fKTMoDKKySz"
   },
   "source": [
    "## Generar Resultados Finales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QriJxcsrJaPW"
   },
   "outputs": [],
   "source": [
    "def analyze_global_metrics(results_df):\n",
    "  # Preparar e imprimir las visualizaciones usando nuestra funcion\n",
    "  visualize_global_metrics(results_df)\n",
    "\n",
    "  # Analisis estadistico usando nuestra funcion\n",
    "  analyze_significance(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jB8s_k35QMed"
   },
   "source": [
    "### **FALTA POR IMPLEMENTAR**: Testeo de Parámetros para Ejecución Global\n",
    "Queda ejecutado con parámetros:\n",
    "- top_n = 10\n",
    "- k = 5\n",
    "- alpha_hybrid=0.5\n",
    "- beta_lt=0.4\n",
    "- lambda_ips=0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbDirXKWRmat"
   },
   "outputs": [],
   "source": [
    "# Obtener dataframe de resultados\n",
    "results_df = global_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
    "\n",
    "# Analisis estadistico usando nuestra funcion\n",
    "analyze_global_metrics(results_df)\n",
    "\n",
    "# Guardar dataframe de resultados\n",
    "results_df.to_csv('global_metrics_results.csv', index=False)\n",
    "print(\"DataFrame de resultados guardado en 'global_metrics_results.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCcyp5g0fQeL"
   },
   "source": [
    "Graficar ahora con distintos `top_n`para ver como se comportan las metricas de los distintos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "leb3IjW-orbg"
   },
   "outputs": [],
   "source": [
    "# Actualización de los modelos\n",
    "models = ['most_popular', 'iknn', 'hybrid', 'random']\n",
    "metrics = ['MAP', 'nDCG', 'Precision', 'Recall', 'User_Diversity', 'Long_Tail', 'Shannon_Entropy',\n",
    "           'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
    "top_n_list = [5, 10, 15, 20, 25]\n",
    "k_category_list = [3, 5, 7]\n",
    "\n",
    "# Crear datos simulados nuevamente para incluir los modelos actualizados\n",
    "data = []\n",
    "for model in models:\n",
    "    for k in k_category_list:\n",
    "        for top_n in top_n_list:\n",
    "            values = np.random.rand(len(metrics))\n",
    "            data.append([model, k, top_n] + list(values))\n",
    "\n",
    "# Crear DataFrame actualizado\n",
    "columns = ['model', 'k', 'top_n'] + metrics\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Crear figura con filas como k y columnas como métricas\n",
    "fig, axes = plt.subplots(len(k_category_list), len(metrics), figsize=(40, 12), sharex=True, sharey=False)\n",
    "fig.suptitle(\"Metrics across Top N values for different k\", fontsize=16)\n",
    "\n",
    "for i, k in enumerate(k_category_list):\n",
    "    df_k = df[df['k'] == k]  # Filtrar por k\n",
    "\n",
    "    for j, metric in enumerate(metrics):\n",
    "        ax = axes[i, j]\n",
    "        for model in models:\n",
    "            df_model = df_k[df_k['model'] == model]\n",
    "            ax.plot(df_model['top_n'], df_model[metric], label=model, marker='o')\n",
    "\n",
    "        if i == 0:  # Títulos de las columnas (métricas)\n",
    "            ax.set_title(metric)\n",
    "\n",
    "        if j == 0:  # Etiquetas para cada fila (k)\n",
    "            ax.set_ylabel(f\"k={k}\")\n",
    "\n",
    "        ax.grid(True)\n",
    "        if i == len(k_category_list) - 1:  # Etiqueta del eje X solo en la última fila\n",
    "            ax.set_xlabel(\"Top N\")\n",
    "\n",
    "        if i == 0 and j == len(metrics) - 1:  # Solo una vez, agregar leyenda\n",
    "            ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferperezh/IIC3633_ProyectoMetricaDiversidad/blob/IKNN/pelicula/pelicula_metrica_diversidad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlgUktzAgpDd"
      },
      "source": [
        "# Métrica **Diversidad de Usuario** en la Película"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZGEvrNhg04J"
      },
      "source": [
        "## Importar los datos\n",
        "Es necesario agregar el archivo \"kaggle.json\" disponible en el repositorio al entorno de archivos del Colab:\n",
        "- https://github.com/ferperezh/IIC3633_ProyectoMetricaDiversidad/blob/main/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cyOa1v13lzbj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cb56609-51ec-4336-dff5-83b314883e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# Crear el directorio .kaggle en Colab\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# Mover el archivo kaggle.json al directorio .kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Cambiar los permisos del archivo kaggle.json para asegurar privacidad\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voZmyq50pPvk",
        "outputId": "9595d206-5f56-4c8d-bc87-8f66efc0c67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Collecting fastFM\n",
            "  Downloading fastFM-0.2.10.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastFM) (1.13.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fastFM) (3.0.11)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastFM) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastFM) (3.5.0)\n",
            "Building wheels for collected packages: fastFM\n",
            "  Building wheel for fastFM (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastFM: filename=fastFM-0.2.10-cp310-cp310-linux_x86_64.whl size=591781 sha256=6126805d741f792610f9001bd7e2b038195db6f84939ab903576351a5ab86dfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/92/52/2da7997fcb7a7ce9042ff3b33836ef0c2fd47aa95382d7a113\n",
            "Successfully built fastFM\n",
            "Installing collected packages: fastFM\n",
            "Successfully installed fastFM-0.2.10\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install fastFM\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtEW04WVpTUP",
        "outputId": "de057bca-e679-4b3a-9091-a102b5fb2be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset\n",
            "License(s): unknown\n",
            "Downloading movielens-20m-dataset.zip to /content\n",
            " 96% 188M/195M [00:01<00:00, 136MB/s]\n",
            "100% 195M/195M [00:01<00:00, 146MB/s]\n",
            "Path to dataset files: movielens-20m-dataset\n"
          ]
        }
      ],
      "source": [
        "# Descargar el dataset\n",
        "!kaggle datasets download -d grouplens/movielens-20m-dataset\n",
        "\n",
        "# Descomprimir el archivo zip descargado\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"movielens-20m-dataset.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"movielens-20m-dataset\")\n",
        "\n",
        "print(\"Path to dataset files: movielens-20m-dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am1WAVqMhLyb"
      },
      "source": [
        "## Procesamiento de Datasets Peliculas\n",
        "Consideramos la tabla `ratings` para tener los ratings que un usuario le da a una pelicula dad. Por lo que obetenemos el promedio de rating que da cada usuario y luego consideramos solo las peliculas que estan sobre el promedio de cada usario. Esas vamos a considerar como las peliculas del usuario. Para luego hacer el join con `movie` mara obtener la metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "baklulfhpbjD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "genome_scores = pd.read_csv('movielens-20m-dataset/genome_scores.csv')\n",
        "genome_tags = pd.read_csv('movielens-20m-dataset/genome_tags.csv')\n",
        "links = pd.read_csv('movielens-20m-dataset/link.csv')\n",
        "movies = pd.read_csv('movielens-20m-dataset/movie.csv')\n",
        "ratings = pd.read_csv('movielens-20m-dataset/rating.csv')\n",
        "tags = pd.read_csv('movielens-20m-dataset/tag.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraer muestra de ratings y movies"
      ],
      "metadata": {
        "id": "J-iJDEa7TbsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings.shape[0], ratings.columns"
      ],
      "metadata": {
        "id": "LvuEd78UTf88",
        "outputId": "bde7e07f-3eee-4a20-ca26-8f35fa586ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000263, Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings['userId'].nunique(), ratings['movieId'].nunique()"
      ],
      "metadata": {
        "id": "dFrhpxYCZFiX",
        "outputId": "cc420494-ec69-411c-c366-5679048421ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(138493, 26744)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies.shape[0], movies.columns"
      ],
      "metadata": {
        "id": "DfW37gHnTnDK",
        "outputId": "3873381d-0f3d-4710-9745-2aec35d3d3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27278, Index(['movieId', 'title', 'genres'], dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir ratings para obtener el 5% de los userId\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "user_ids = ratings['userId'].unique()\n",
        "train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.05, random_state=42)\n"
      ],
      "metadata": {
        "id": "T_9d9dpCZ4EN"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_user_ids.shape[0], test_user_ids.shape[0]"
      ],
      "metadata": {
        "id": "iM0pq_lcaVHr",
        "outputId": "2e8ac48a-f0d6-4f5a-b7f9-923e8901d7df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131568, 6925)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_sample = ratings[ratings['userId'].isin(test_user_ids)]"
      ],
      "metadata": {
        "id": "ljbq4tghaerS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' # Muestra de los datos el 5%\n",
        "from sklearn.model_selection import train_test_split\n",
        "_, ratings_sample = train_test_split(ratings,\n",
        "    test_size=0.05,  # Reducir a un 5% el tamaño del dataset total\n",
        "    random_state=42\n",
        ") '''"
      ],
      "metadata": {
        "id": "FG8Rad0dTa95",
        "outputId": "9f3d8b79-7f38-4053-b0c1-83f533a4bd16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' # Muestra de los datos el 5%\\nfrom sklearn.model_selection import train_test_split\\n_, ratings_sample = train_test_split(ratings,\\n    test_size=0.05,  # Reducir a un 5% el tamaño del dataset total\\n    random_state=42\\n) '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_sample.shape[0]"
      ],
      "metadata": {
        "id": "pyGI20SkUbxk",
        "outputId": "8658f784-b318-416e-a0cb-c4aaff06ae18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1002612"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "HTopHB3oaEoF",
        "outputId": "ba69e5f0-14ef-4d5b-8a6b-6da37c937ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-c6b5049be53e>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ratings_sample['rating_mean'] = ratings_sample['userId'].map(ratings_por_usuario)\n"
          ]
        }
      ],
      "source": [
        "# Agrupar por usuario la tabla raitings para tener el rating promedio que le da a las peliculas\n",
        "ratings_por_usuario = ratings_sample.groupby('userId')['rating'].mean()\n",
        "# Hacemos un round a la decima\n",
        "ratings_por_usuario = ratings_por_usuario.round(1)\n",
        "ratings_por_usuario\n",
        "\n",
        "# Ahora agregamos la columna rating_mean a la tabla rating con esta informacion\n",
        "ratings_sample['rating_mean'] = ratings_sample['userId'].map(ratings_por_usuario)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "STDj83WdaFvq"
      },
      "outputs": [],
      "source": [
        "# Filtramos por todos los ratings que son mayor o igual al rating_mean\n",
        "ratings_filtrados = ratings_sample[ratings_sample['rating'] >= ratings_sample['rating_mean']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbTYnKFCaTL4"
      },
      "source": [
        "Ahora las conectamos `ratings_filtrados` con la metada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "dWO3XS7oaaC3"
      },
      "outputs": [],
      "source": [
        "#Merge de ratings filtrados con movies\n",
        "movies_data = pd.merge(ratings_filtrados, movies, on='movieId', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gzXHFjL-apNe"
      },
      "outputs": [],
      "source": [
        "#movies_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ2AjqFqanfV"
      },
      "source": [
        "Vemos que por pelicula tenemos varios generos separados por | . Pero consideremos todos los genermos por separados todos esos generos representan el genero de la pelicula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5pBUW8olbVv8"
      },
      "outputs": [],
      "source": [
        "#movies_data['genre_list'] = movies_data['genres'].str.split('|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PDqePy5wgZJs"
      },
      "outputs": [],
      "source": [
        "#movies_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tomamos el genero relevante como el primero que parece de la lista"
      ],
      "metadata": {
        "id": "_-JX1QlfJ36B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wEhx_BFLGpV",
        "outputId": "33a49c7d-707e-4696-fa98-7dae2ec4a3e7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "562860"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar por todos los usarios que tienen mas de una recomendacion\n",
        "user_counts = movies_data['userId'].value_counts()\n",
        "valid_users = user_counts[user_counts > 4].index\n",
        "movies_data = movies_data[movies_data['userId'].isin(valid_users)]"
      ],
      "metadata": {
        "id": "g4q28wtFvCOl"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' # Muestra de los datos el 10%\n",
        "from sklearn.model_selection import train_test_split\n",
        "_, movies_data = train_test_split(movies_data,\n",
        "    test_size=0.1,  # Reducir a un 10% el tamaño del dataset total\n",
        "    stratify=movies_data['userId'],  # Estratificar por usuario\n",
        "    random_state=24\n",
        ") '''\n",
        "\n"
      ],
      "metadata": {
        "id": "jKdUHBJLs0Jx",
        "outputId": "6ff9e7a3-47a6-49e5-9feb-1151c4429ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" # Muestra de los datos el 10%\\nfrom sklearn.model_selection import train_test_split\\n_, movies_data = train_test_split(movies_data,\\n    test_size=0.1,  # Reducir a un 10% el tamaño del dataset total\\n    stratify=movies_data['userId'],  # Estratificar por usuario\\n    random_state=24\\n) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_data['relevant_genre'] = movies_data['genres'].str.split('|').str[0]"
      ],
      "metadata": {
        "id": "nBa6Gzv-J7Uf"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "5wA-dA7SL5hW",
        "outputId": "9ad96b68-faf9-4d76-dc71-77b04feb7a0f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        userId  movieId  rating            timestamp  rating_mean  \\\n",
              "0           36      145     3.5  2011-06-07 01:33:55          2.8   \n",
              "1           36      163     3.0  2011-06-07 01:30:22          2.8   \n",
              "2           36      196     3.0  2011-06-07 01:32:53          2.8   \n",
              "3           36     1088     3.0  2011-06-07 01:35:01          2.8   \n",
              "4           36     1358     3.5  2011-06-07 01:33:00          2.8   \n",
              "...        ...      ...     ...                  ...          ...   \n",
              "562855  138489     2959     4.5  2012-11-15 14:35:14          4.0   \n",
              "562856  138489     3671     4.0  2012-11-15 14:18:27          4.0   \n",
              "562857  138489     4973     4.0  2012-11-15 14:35:24          4.0   \n",
              "562858  138489     5291     4.5  2012-11-15 14:35:58          4.0   \n",
              "562859  138489    58559     4.0  2012-11-15 14:21:49          4.0   \n",
              "\n",
              "                                                    title  \\\n",
              "0                                         Bad Boys (1995)   \n",
              "1                                        Desperado (1995)   \n",
              "2                                          Species (1995)   \n",
              "3                                    Dirty Dancing (1987)   \n",
              "4                                      Sling Blade (1996)   \n",
              "...                                                   ...   \n",
              "562855                                  Fight Club (1999)   \n",
              "562856                             Blazing Saddles (1974)   \n",
              "562857  Amelie (Fabuleux destin d'Amélie Poulain, Le) ...   \n",
              "562858                         Rashomon (Rashômon) (1950)   \n",
              "562859                            Dark Knight, The (2008)   \n",
              "\n",
              "                                    genres relevant_genre  \n",
              "0       Action|Comedy|Crime|Drama|Thriller         Action  \n",
              "1                   Action|Romance|Western         Action  \n",
              "2                            Horror|Sci-Fi         Horror  \n",
              "3                    Drama|Musical|Romance          Drama  \n",
              "4                                    Drama          Drama  \n",
              "...                                    ...            ...  \n",
              "562855         Action|Crime|Drama|Thriller         Action  \n",
              "562856                      Comedy|Western         Comedy  \n",
              "562857                      Comedy|Romance         Comedy  \n",
              "562858                 Crime|Drama|Mystery          Crime  \n",
              "562859             Action|Crime|Drama|IMAX         Action  \n",
              "\n",
              "[562839 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9f48749-1b54-46ca-ab1e-792a97d2de2a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating_mean</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>relevant_genre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36</td>\n",
              "      <td>145</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2011-06-07 01:33:55</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Bad Boys (1995)</td>\n",
              "      <td>Action|Comedy|Crime|Drama|Thriller</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>36</td>\n",
              "      <td>163</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2011-06-07 01:30:22</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Desperado (1995)</td>\n",
              "      <td>Action|Romance|Western</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>36</td>\n",
              "      <td>196</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2011-06-07 01:32:53</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Species (1995)</td>\n",
              "      <td>Horror|Sci-Fi</td>\n",
              "      <td>Horror</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>1088</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2011-06-07 01:35:01</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Dirty Dancing (1987)</td>\n",
              "      <td>Drama|Musical|Romance</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>1358</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2011-06-07 01:33:00</td>\n",
              "      <td>2.8</td>\n",
              "      <td>Sling Blade (1996)</td>\n",
              "      <td>Drama</td>\n",
              "      <td>Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562855</th>\n",
              "      <td>138489</td>\n",
              "      <td>2959</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2012-11-15 14:35:14</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Fight Club (1999)</td>\n",
              "      <td>Action|Crime|Drama|Thriller</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562856</th>\n",
              "      <td>138489</td>\n",
              "      <td>3671</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2012-11-15 14:18:27</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Blazing Saddles (1974)</td>\n",
              "      <td>Comedy|Western</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562857</th>\n",
              "      <td>138489</td>\n",
              "      <td>4973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2012-11-15 14:35:24</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Amelie (Fabuleux destin d'Amélie Poulain, Le) ...</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562858</th>\n",
              "      <td>138489</td>\n",
              "      <td>5291</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2012-11-15 14:35:58</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Rashomon (Rashômon) (1950)</td>\n",
              "      <td>Crime|Drama|Mystery</td>\n",
              "      <td>Crime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562859</th>\n",
              "      <td>138489</td>\n",
              "      <td>58559</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2012-11-15 14:21:49</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Dark Knight, The (2008)</td>\n",
              "      <td>Action|Crime|Drama|IMAX</td>\n",
              "      <td>Action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>562839 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9f48749-1b54-46ca-ab1e-792a97d2de2a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d9f48749-1b54-46ca-ab1e-792a97d2de2a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d9f48749-1b54-46ca-ab1e-792a97d2de2a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-29aaf10a-ded3-46bf-ad21-cf3eb8892564\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29aaf10a-ded3-46bf-ad21-cf3eb8892564')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-29aaf10a-ded3-46bf-ad21-cf3eb8892564 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_218e21a7-3711-4c5a-a4cd-fcf5d2bcc34a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('movies_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_218e21a7-3711-4c5a-a4cd-fcf5d2bcc34a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('movies_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movies_data"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGslOVr2dCPw"
      },
      "source": [
        "Luego generemos un dicionario para contar con la lista de generos por pelicula. Donde contamos por usario que categorias son y cuantas. Pero el código demora mucha en correr por lo que se cuardar en el colab.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Tjo-mlHibhV3",
        "outputId": "b85a4287-437d-419a-dd5f-f345fbf8b624"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" # Crear un diccionario para contar los géneros de cada usuario\\nuser_genre_counts = {}\\n\\nfor index, row in movies_data.iterrows():\\n    user_id = row['userId']\\n    genres = row['genre_list']\\n\\n    if user_id not in user_genre_counts:\\n        user_genre_counts[user_id] = {}\\n\\n    for genre in genres:\\n      if genre not in user_genre_counts[user_id]:\\n          user_genre_counts[user_id][genre] =  0\\n      user_genre_counts[user_id][genre] += 1 \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "''' # Crear un diccionario para contar los géneros de cada usuario\n",
        "user_genre_counts = {}\n",
        "\n",
        "for index, row in movies_data.iterrows():\n",
        "    user_id = row['userId']\n",
        "    genres = row['genre_list']\n",
        "\n",
        "    if user_id not in user_genre_counts:\n",
        "        user_genre_counts[user_id] = {}\n",
        "\n",
        "    for genre in genres:\n",
        "      if genre not in user_genre_counts[user_id]:\n",
        "          user_genre_counts[user_id][genre] =  0\n",
        "      user_genre_counts[user_id][genre] += 1 '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88iV9RoQc4zN"
      },
      "source": [
        "Debes hacer una conexion con tu colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Zvv7QAg5cz_8",
        "outputId": "4ab3a1e9-9088-40dd-f1da-a61753d5724a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" from google.colab import drive\\ndrive.mount('/content/drive')\\n\\npath = '/content/drive/MyDrive/IIC3633-2024-2/user_genre_counts.csv' \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "''' from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/IIC3633-2024-2/user_genre_counts.csv' '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Q_nIiiHces47",
        "outputId": "e13ffd58-dc7c-4e13-cefd-e36d63b3640a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" # Guardar user_genre_counts\\nimport json\\n\\nwith open(path, 'w') as file:\\n    json.dump(user_genre_counts, file) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "''' # Guardar user_genre_counts\n",
        "import json\n",
        "\n",
        "with open(path, 'w') as file:\n",
        "    json.dump(user_genre_counts, file) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8QM8t2Zqe4Cz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7bba976d-9cfa-4a2e-d18b-c13f42ece36b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" # Obtener user_genre_counts\\nimport json\\n\\nwith open(path, 'r') as file:\\n    user_genre_counts = json.load(file) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "''' # Obtener user_genre_counts\n",
        "import json\n",
        "\n",
        "with open(path, 'r') as file:\n",
        "    user_genre_counts = json.load(file) '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMFEX6zypmto"
      },
      "source": [
        "## Categorización de cada usuario\n",
        "Obtenemos el top k=5 de categorias de cada usuario"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "RzAFpTE9pr7O",
        "outputId": "4555bf17-4007-4ed1-ecd6-f0b80ca63888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' # Calcular las k categorías más vistas por cada usuario\\nk = 5\\ntop_k_genres_data = []\\n\\n# Itera sobre cada usuario en user\\nfor user_id, genres in user_genre_counts.items():\\n  # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\\n   sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\\n   for genre, _ in sorted_genres:\\n    top_k_genres_data.append({\\n        \\'userId\\': user_id,\\n        \\'genre_principal\\': genre,\\n        \\'count\\': genres[genre]\\n    })\\n\\n\\ntop_k_5_categories_total = pd.DataFrame(top_k_genres_data)\\n\\n# Mostrar los resultados\\nprint(\"Top k = 5 géneros más vistos por usuario:\")\\ntop_k_5_categories_total '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "''' # Calcular las k categorías más vistas por cada usuario\n",
        "k = 5\n",
        "top_k_genres_data = []\n",
        "\n",
        "# Itera sobre cada usuario en user\n",
        "for user_id, genres in user_genre_counts.items():\n",
        "  # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\n",
        "   sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "   for genre, _ in sorted_genres:\n",
        "    top_k_genres_data.append({\n",
        "        'userId': user_id,\n",
        "        'genre_principal': genre,\n",
        "        'count': genres[genre]\n",
        "    })\n",
        "\n",
        "\n",
        "top_k_5_categories_total = pd.DataFrame(top_k_genres_data)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Top k = 5 géneros más vistos por usuario:\")\n",
        "top_k_5_categories_total '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rofvl7IXiKfH"
      },
      "source": [
        "# Generar Recomendaciones\n",
        "\n",
        "Se probará con diferentes métodos de recomendación para evaluar los resultados del modelo:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE9RoNZUvFxt"
      },
      "source": [
        "## Método Most Popular:\n",
        "Recomienda las peliculas más vistas o mejor rankeadas en el conjunto global de datos de entrenamiento.\n",
        "- Cuenta y ordena las peliculas según número de reproducciones\n",
        "- Selecciona las `k peliculas` más populares\n",
        "- Alta probabilidad de recomendar contenido con hartas visualizaciones\n",
        "- Mismo resultado para todos los usuarios\n",
        "- Baja diversidad de recomendaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff216W1UgoxT",
        "outputId": "e14534cc-3ad5-437d-cf9d-c54af3d3801a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['userId', 'movieId', 'rating', 'timestamp', 'rating_mean', 'title',\n",
              "       'genres', 'relevant_genre'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "movies_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "irOe5VtQgvkv"
      },
      "outputs": [],
      "source": [
        "data_movie = movies_data[['userId', 'movieId', 'title', 'relevant_genre']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR7XUSqzlj4V",
        "outputId": "a2cc3306-46b9-4349-81bc-9b59d239c2aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6919"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "data_movie['userId'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Rmy66VM13nB0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Filtrar usuarios con al menos 1 filas\n",
        "user_counts = data_movie['userId'].value_counts()\n",
        "valid_users = user_counts[user_counts > 1].index\n",
        "filtered_data = data_movie[data_movie['userId'].isin(valid_users)]\n",
        "\n",
        "data_movie_train, data_movie_test = train_test_split(\n",
        "    filtered_data,\n",
        "    test_size=0.2,\n",
        "    stratify=filtered_data['userId'],  # Stratificar por `userId`\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_movie_train['userId'].nunique(), data_movie_train.shape[0]"
      ],
      "metadata": {
        "id": "yQI89xWVnSXb",
        "outputId": "5604c685-9498-4bc7-b29a-37ab4527474f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6919, 450271)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3sVRhbCgR-i",
        "outputId": "03322a9f-e4ce-4a32-d0a8-1d392f7328b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6919, 112568)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "data_movie_test['userId'].nunique(), data_movie_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contar la cantidad de recomendaciones por userId\n",
        "data_movie_train['userId'].value_counts().min(), data_movie_test['userId'].value_counts().min()"
      ],
      "metadata": {
        "id": "CyV0bmSonhEx",
        "outputId": "52e53e8b-c691-44c4-8381-b017c82a179e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK0GMu3qzn6P"
      },
      "source": [
        "### Obtención de Top K Categorías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "m90169imu7Rc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "602f6ee8-b64d-4a95-82e7-dbe6d04061cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" user_genre_counts_test = {}\\n\\nfor index, row in data_movie_test.iterrows():\\n    user_id = row['userId']\\n    genres = row['genre_list']\\n\\n    if user_id not in user_genre_counts_test:\\n        user_genre_counts_test[user_id] = {}\\n\\n    for genre in genres:\\n      if genre not in user_genre_counts_test[user_id]:\\n          user_genre_counts_test[user_id][genre] =  0\\n      user_genre_counts_test[user_id][genre] += 1 \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "''' user_genre_counts_test = {}\n",
        "\n",
        "for index, row in data_movie_test.iterrows():\n",
        "    user_id = row['userId']\n",
        "    genres = row['genre_list']\n",
        "\n",
        "    if user_id not in user_genre_counts_test:\n",
        "        user_genre_counts_test[user_id] = {}\n",
        "\n",
        "    for genre in genres:\n",
        "      if genre not in user_genre_counts_test[user_id]:\n",
        "          user_genre_counts_test[user_id][genre] =  0\n",
        "      user_genre_counts_test[user_id][genre] += 1 '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OURJIAacvL1x"
      },
      "outputs": [],
      "source": [
        "#path = \"/content/drive/MyDrive/IIC3633-2024-2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YD3HSvUNvNhy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c74c428a-c112-4a32-9188-3e03c74ad5f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" #Guardar user_genre_counts_test and data_movie_train and data_movie_test\\nimport csv\\n\\nwith open(path+'data_movie_train.csv', 'w') as file:\\n    writer = csv.writer(file)\\n    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\\n    writer.writerows(data_movie_train.values)\\n\\nwith open(path+'data_movie_test.csv', 'w') as file:\\n    writer = csv.writer(file)\\n    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\\n    writer.writerows(data_movie_test.values) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "''' #Guardar user_genre_counts_test and data_movie_train and data_movie_test\n",
        "import csv\n",
        "\n",
        "with open(path+'data_movie_train.csv', 'w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\n",
        "    writer.writerows(data_movie_train.values)\n",
        "\n",
        "with open(path+'data_movie_test.csv', 'w') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['userId', 'movieId', 'title', 'genre_list'])\n",
        "    writer.writerows(data_movie_test.values) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kqBGWtd5zRT8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e7ddb92d-f1b6-4b8c-82e1-6248d38afcf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" import json\\n\\nwith open(path+'user_genre_counts_test.csv', 'w') as file:\\n    json.dump(user_genre_counts_test, file) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "''' import json\n",
        "\n",
        "with open(path+'user_genre_counts_test.csv', 'w') as file:\n",
        "    json.dump(user_genre_counts_test, file) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6Rgz0YncvTkz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "3d1baa1f-ce9b-4ef7-9bff-08ce9a9fbd6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" #Obtener user_genre_counts_test and data_movie_train and data_movie_test\\nimport csv\\n\\nwith open(path+'data_movie_train.csv', 'r') as file:\\n    reader = csv.reader(file)\\n    next(reader)  # Saltar la primera fila (encabezados)\\n    data_movie_train = list(reader)\\n    data_movie_train = pd.DataFrame(data_movie_train, columns=['userId', 'movieId', 'title', 'genre_list'])\\n    data_movie_train['genre_list'] = data_movie_train['genre_list'].apply(lambda x: x.split(','))\\n\\nwith open(path+'data_movie_test.csv', 'r') as file:\\n    reader = csv.reader(file)\\n    next(reader)  # Saltar la primera fila (encabezados)\\n    data_movie_test = list(reader)\\n    data_movie_test = pd.DataFrame(data_movie_test, columns=['userId', 'movieId', 'title', 'genre_list'])\\n    data_movie_test['genre_list'] = data_movie_test['genre_list'].apply(lambda x: x.split(',')) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "''' #Obtener user_genre_counts_test and data_movie_train and data_movie_test\n",
        "import csv\n",
        "\n",
        "with open(path+'data_movie_train.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Saltar la primera fila (encabezados)\n",
        "    data_movie_train = list(reader)\n",
        "    data_movie_train = pd.DataFrame(data_movie_train, columns=['userId', 'movieId', 'title', 'genre_list'])\n",
        "    data_movie_train['genre_list'] = data_movie_train['genre_list'].apply(lambda x: x.split(','))\n",
        "\n",
        "with open(path+'data_movie_test.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Saltar la primera fila (encabezados)\n",
        "    data_movie_test = list(reader)\n",
        "    data_movie_test = pd.DataFrame(data_movie_test, columns=['userId', 'movieId', 'title', 'genre_list'])\n",
        "    data_movie_test['genre_list'] = data_movie_test['genre_list'].apply(lambda x: x.split(',')) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "OXVjjqkyzeVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b199088e-b6ce-4a98-bd37-798cd74781fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" import json\\n\\nwith open(path+'user_genre_counts_test.csv', 'r') as file:\\n    user_genre_counts_test = json.load(file) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "''' import json\n",
        "\n",
        "with open(path+'user_genre_counts_test.csv', 'r') as file:\n",
        "    user_genre_counts_test = json.load(file) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "mWLjJ3y4ZkvC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "00e51b05-8129-4200-a99f-7c238198e972"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" def get_top_k_categories(df, k):\\n  top_k_genres_data = []\\n\\n  # Itera sobre cada usuario en user\\n  for user_id, genres in user_genre_counts_test.items():\\n    # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\\n    sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\\n    for genre, _ in sorted_genres:\\n      top_k_genres_data.append({\\n          'userId': user_id,\\n          'genre_principal': genre,\\n          'count': genres[genre]\\n      })\\n\\n\\n  top_k_5_categories_total = pd.DataFrame(top_k_genres_data)\\n\\n  return top_k_5_categories_total \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "''' def get_top_k_categories(df, k):\n",
        "  top_k_genres_data = []\n",
        "\n",
        "  # Itera sobre cada usuario en user\n",
        "  for user_id, genres in user_genre_counts_test.items():\n",
        "    # Ordenar los los géneros por el conteo en orden descendente y tomar los k más altos\n",
        "    sorted_genres = sorted(genres.items(), key=lambda x: x[1], reverse=True)[:k]\n",
        "    for genre, _ in sorted_genres:\n",
        "      top_k_genres_data.append({\n",
        "          'userId': user_id,\n",
        "          'genre_principal': genre,\n",
        "          'count': genres[genre]\n",
        "      })\n",
        "\n",
        "\n",
        "  top_k_5_categories_total = pd.DataFrame(top_k_genres_data)\n",
        "\n",
        "  return top_k_5_categories_total '''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_categories(df, k):\n",
        "  user_genre_df = df[['userId', 'relevant_genre']]\n",
        "\n",
        "  # Calcular las k categorías más escuchadas por cada usuario\n",
        "  top_k_categories = (\n",
        "      user_genre_df.groupby(['userId', 'relevant_genre'])\n",
        "      .size()  # Contar ocurrencias de cada género por usuario\n",
        "      .reset_index(name='count')  # Resetear índice y nombrar la columna de conteo\n",
        "      .sort_values(['userId', 'count'], ascending=[True, False])  # Ordenar por usuario y luego por conteo descendente\n",
        "      .groupby('userId')  # Agrupar por usuario para obtener los top-k\n",
        "      .head(k)  # Tomar los K géneros más escuchados por usuario\n",
        "  )\n",
        "\n",
        "  return top_k_categories"
      ],
      "metadata": {
        "id": "4cOv9yicNwWI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ7B5xYiztSV"
      },
      "source": [
        "### Recomendación de Most Popular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "BI2wF-vQbvv-"
      },
      "outputs": [],
      "source": [
        "list_recomendation = None\n",
        "\n",
        "def recommend_most_popular(user, data_train, k=10):\n",
        "  global list_recomendation\n",
        "  if list_recomendation is not None:\n",
        "    return list_recomendation\n",
        "  # Agrugar por pelicula contando la cantidad de apariciones\n",
        "  data_movie_count = data_train.groupby('movieId')['movieId'].count().reset_index(name='popularity')\n",
        "\n",
        "  # Ordenar por popularity\n",
        "  data_movie_count = data_movie_count.sort_values('popularity', ascending=False)\n",
        "  top_k_popular_movie = data_movie_count.head(k)\n",
        "\n",
        "  top_k_popular_movie = top_k_popular_movie['movieId'].tolist()\n",
        "\n",
        "  list_recomendation = top_k_popular_movie\n",
        "\n",
        "  return top_k_popular_movie\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Rzlv7UvY_r"
      },
      "source": [
        "## Método Random\n",
        "Recomienda peliculas de manera aleatoria del conjunto de entrenamiento.\n",
        "- Selecciona `k` peliculas aleatorias\n",
        "- Usado como baseline para comparaciones\n",
        "- Debiese mostrar un aumento en la diversidad de las recomendaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "G3X_e8PZyyoU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def recommend_random(user, data_train, k=10):\n",
        "  # Obtener todas las peliculas unicas\n",
        "  unique_movies = data_train['movieId'].unique()\n",
        "\n",
        "  # Seleccionar k peliculas aleatorias\n",
        "  random_movies = random.sample(list(unique_movies), min(k, len(unique_movies)))\n",
        "\n",
        "  return random_movies\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método FastFM\n",
        "FastFM es un modelo basado en Factorization Machines, utilizado para generar recomendaciones. Este enfoque:\n",
        "\n",
        "- Aprende interacciones latentes entre usuarios y canciones a partir de datos dispersos.\n",
        "- Es especialmente eficaz para integrar tanto características del usuario como del contenido, además de las interacciones implícitas.\n",
        "- Emplea técnicas de factorización matricial y optimización eficiente para manejar grandes conjuntos de datos."
      ],
      "metadata": {
        "id": "niodAzFSOffD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from fastFM import sgd\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "def recommend_fastfm(user, data_train, k=10):\n",
        "# COLUMNAS: userId, movieId, title, relevant_genre\n",
        "  # Creamos matriz de interacción\n",
        "  us_matrix = pd.pivot_table(\n",
        "    data_train,\n",
        "    index='userId',\n",
        "    columns='title',\n",
        "    values='movieId',\n",
        "    aggfunc='count',\n",
        "    fill_value=0\n",
        "  )\n",
        "  # Expandir matriz en formato largo\n",
        "  interaction_data = us_matrix.stack().reset_index()\n",
        "  interaction_data.columns = ['userId', 'title', 'interaction']\n",
        "  interaction_data['interaction'] = (interaction_data['interaction'] > 0).astype(int)  # Binarización\n",
        "\n",
        "  # Crear matriz dispersa para características\n",
        "  X = sparse.csc_matrix(pd.get_dummies(interaction_data[['userId', 'title']], sparse=True).values)\n",
        "\n",
        "  # Etiquetas (1 si hubo interacción, 0 si no)\n",
        "  y = interaction_data['interaction'].values\n",
        "\n",
        "  # Creamos el modelo de FastFM fit con primera columna de objetivo.\n",
        "  ffm = sgd.FMRegression(n_iter=100, rank=2)\n",
        "  ffm.fit(X, y)\n",
        "\n",
        "  # Obtener vector del usuario para predicciones\n",
        "  user_movie = us_matrix.loc[user]\n",
        "  unseen_movie = user_movie[user_movie == 0].index  # Canciones no escuchadas\n",
        "  user_data = pd.DataFrame({'userId': [user] * len(unseen_movie), 'title': unseen_movie})\n",
        "\n",
        "  # Matriz dispersa para predicciones\n",
        "  feature_columns = pd.get_dummies(interaction_data[['userId', 'title']], sparse=True).columns\n",
        "  X_user = sparse.csc_matrix(pd.get_dummies(user_data, sparse=True).reindex(columns=feature_columns).fillna(0).values)\n",
        "  predicted_ratings = ffm.predict(X_user)\n",
        "\n",
        "  # Ordenar y seleccionar las mejores recomendaciones\n",
        "  user_data['predicted_rating'] = predicted_ratings\n",
        "  top_recommendations = user_data.sort_values('predicted_rating', ascending=False).head(k)['title'].tolist()\n",
        "\n",
        "  return top_recommendations\n"
      ],
      "metadata": {
        "id": "FTZKizPNORS-"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Método DeepFM\n",
        "DeepFM es un modelo avanzado para sistemas de recomendación que combina lo mejor de las Factorization Machines (FMs) y las redes neuronales profundas (Deep Learning) para capturar interacciones complejas entre características. Este enfoque:\n",
        "\n",
        "- Factorization Machines (FMs): Capturan de manera eficiente las interacciones de segundo orden entre características, como usuario y canción, especialmente en datos dispersos.\n",
        "- Redes neuronales profundas: Aprenden interacciones de mayor nivel (no lineales) entre características, mejorando la capacidad del modelo para capturar patrones complejos.\n",
        "- Integra ambos componentes en un solo modelo, compartiendo los mismos embeddings para reducir la redundancia y optimizar el aprendizaje."
      ],
      "metadata": {
        "id": "KwyHZrrXPLBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Creamos el modelo de DeepFM\n",
        "def build_deepfm(input_dim):\n",
        "    # Componente FM\n",
        "    input_movie = keras.layers.Input(shape=(input_dim,))\n",
        "    fm_linear = keras.layers.Dense(1)(input_movie)\n",
        "\n",
        "    # Componente Deep\n",
        "    deep = keras.layers.Dense(256, activation='relu')(input_movie)\n",
        "    deep = keras.layers.Dropout(0.2)(deep)\n",
        "    deep = keras.layers.Dense(128, activation='relu')(deep)\n",
        "    deep = keras.layers.Dense(64, activation='relu')(deep)\n",
        "    deep = keras.layers.Dense(1)(deep)\n",
        "\n",
        "    # Combinar Componentes\n",
        "    fm_deep = keras.layers.Concatenate()([fm_linear, deep])\n",
        "\n",
        "    # Combinar Componentes\n",
        "    output = keras.layers.Add()([fm_linear, deep])\n",
        "\n",
        "    # Modelo\n",
        "    model = keras.Model(inputs=input_movie, outputs=output)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def recommend_deepfm(user, data_train, k=10):\n",
        "  # Generamos subset de datos para evaluar interacción usuario-canción\n",
        "  # COLUMNAS: userId, movieId, title, relevant_relevant_genre\n",
        "  user_movie = data_train[['userId', 'title', 'relevant_genre']]\n",
        "\n",
        "  # Creamos matriz de interacción\n",
        "  us_matrix = pd.pivot_table(\n",
        "    user_movie,\n",
        "    values='relevant_genre',           # Género es el valor de interacción\n",
        "    index='userId',\n",
        "    columns='title',\n",
        "    aggfunc='count',\n",
        "    fill_value=0\n",
        "  )\n",
        "\n",
        "  # Preparar datos para DeepFM\n",
        "  X = us_matrix.values\n",
        "  input_dim = X.shape[1]\n",
        "  y = us_matrix.iloc[:,0].values\n",
        "\n",
        "  # Entrenamos el modelo\n",
        "  model = build_deepfm(input_dim)\n",
        "  model.fit(X, y, epochs=5, batch_size=32, verbose=0)\n",
        "\n",
        "  # Calcular las recomendaciones para el usuario\n",
        "  user_vector = us_matrix.loc[user].values.reshape(1, -1)\n",
        "  predictions = model.predict(user_vector).flatten()\n",
        "\n",
        "  # Seleccionar las Top-K canciones\n",
        "  movie_ids = us_matrix.columns\n",
        "  already_heard = set(user_movie[user_movie['userId'] == user]['title'])\n",
        "\n",
        "  # Filtrar y ordenar las recomendaciones\n",
        "  candidate_movie = [(movie, score) for movie, score in zip(movie_ids, predictions)\n",
        "                    if movie not in already_heard]\n",
        "  # Si no encuentra candidatos, entones se usan las recomendaciones originales\n",
        "  if not candidate_movie:\n",
        "      candidate_movie = [(movie, score) for movie, score in zip(movie_ids, predictions)]\n",
        "\n",
        "  candidate_movie.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "  # Asegurarse de que hayan k recomendaciones\n",
        "  if len(candidate_movie) < k:\n",
        "      # Rellenar con canciones aleatorias si es necesario\n",
        "      available_movie = list(set(movie_ids) - set(movie for movie, _ in candidate_movie))\n",
        "      if available_movie:\n",
        "        padding = random.sample(available_movie, min(k - len(candidate_movie), len(available_movie)))\n",
        "        candidate_movie.extend([(movie, 0.0) for movie in padding])\n",
        "\n",
        "  # Retornar las k recomendaciones\n",
        "  recommendations = [movie for movie, _ in candidate_movie[:k]]\n",
        "\n",
        "  return recommendations\n"
      ],
      "metadata": {
        "id": "EFiY50W8PS-K"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9pOcjT_vgFs"
      },
      "source": [
        "## Método IKNN\n",
        " Recomienda películas usando filtrado colaborativo basado en usuarios (IKNN - Item K-Nearest Neighbors).\n",
        "\n",
        " - Calcula la similitud entre usuarios basada en las películas que han visto\n",
        " - Usa `similitud coseno` para encontrar los k usuarios más similares\n",
        " - Recomienda películas que los usuarios similares han visto pero el usuario actual no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "VWGNdIiF0H65"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "class MovieIKNN:\n",
        "    def __init__(self, k=20):\n",
        "        self.k = k\n",
        "        self.item_similarity = None\n",
        "        self.item_ids = None\n",
        "        self.user_ids = None\n",
        "\n",
        "    def _create_user_item_matrix(self, df):\n",
        "        \"\"\"\n",
        "        Crea matriz usuario-item a partir del dataframe\n",
        "        \"\"\"\n",
        "        # Crear mapeos de IDs únicos\n",
        "        unique_users = df['userId'].unique()\n",
        "        unique_items = df['movieId'].unique()\n",
        "        self.user_ids = {user: idx for idx, user in enumerate(unique_users)}\n",
        "        self.item_ids = {item: idx for idx, item in enumerate(unique_items)}\n",
        "\n",
        "        # Crear matriz de interacciones\n",
        "        rows = []\n",
        "        cols = []\n",
        "        data = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            user_idx = self.user_ids[row['userId']]\n",
        "            item_idx = self.item_ids[row['movieId']]\n",
        "            rows.append(user_idx)\n",
        "            cols.append(item_idx)\n",
        "            data.append(1)  # 1 para indicar interacción\n",
        "\n",
        "        return csr_matrix((data, (rows, cols)),\n",
        "                         shape=(len(unique_users), len(unique_items)))\n",
        "\n",
        "    def fit(self, df):\n",
        "        \"\"\"\n",
        "        Entrena el modelo con el dataframe de interacciones\n",
        "        \"\"\"\n",
        "        # Crear matriz usuario-item\n",
        "        self.user_item_matrix = self._create_user_item_matrix(df)\n",
        "\n",
        "        # Calcular similitud entre items\n",
        "        self.item_similarity = cosine_similarity(self.user_item_matrix.T)\n",
        "        # Evitar que la similitud consigo mismo sea 1\n",
        "        np.fill_diagonal(self.item_similarity, 0)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def recommend(self, username, df, n_recommendations=10):\n",
        "        \"\"\"\n",
        "        Genera recomendaciones para un usuario\n",
        "        \"\"\"\n",
        "        if username not in self.user_ids:\n",
        "            print(f\"Usuario {username} no encontrado en el dataset\")\n",
        "            return []\n",
        "\n",
        "        # Obtener índice del usuario\n",
        "        user_idx = self.user_ids[username]\n",
        "\n",
        "        # Obtener vector de interacciones del usuario\n",
        "        user_vector = self.user_item_matrix[user_idx].toarray().flatten()\n",
        "\n",
        "        # Calcular predicciones\n",
        "        predictions = self._predict(user_vector)\n",
        "\n",
        "        # Poner -inf en items ya escuchados\n",
        "        predictions[user_vector > 0] = float('-inf')\n",
        "\n",
        "        # Obtener top N recomendaciones\n",
        "        top_idx = np.argsort(predictions)[::-1][:n_recommendations]\n",
        "\n",
        "        # Convertir índices a nombres de canciones\n",
        "        reverse_item_ids = {v: k for k, v in self.item_ids.items()}\n",
        "        recommendations = [reverse_item_ids[idx] for idx in top_idx]\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def _predict(self, user_vector):\n",
        "        \"\"\"\n",
        "        Genera predicciones para un vector de usuario\n",
        "        \"\"\"\n",
        "        # Calcular predicciones usando similitud de items\n",
        "        predictions = np.dot(self.item_similarity, user_vector)\n",
        "\n",
        "        # Normalizar predicciones\n",
        "        sim_sums = np.sum(np.abs(self.item_similarity), axis=0)\n",
        "        sim_sums[sim_sums == 0] = 1  # Evitar división por cero\n",
        "        predictions = predictions / sim_sums\n",
        "\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSdxrY_viR4"
      },
      "source": [
        "## Método Híbrido\n",
        "Método híbrido que combina popularidad con similtud de géneros según parámetro `alpha`.\n",
        "\n",
        "Basado parcialmente en el [Siguiente Articulo](https://marketsy.ai/blog/hybrid-recommender-systems-beginners-guide).\n",
        "\n",
        "- `alpha`: Parámetro para balancear entre popularidad global (`1-alpha`) y preferencias de género del usuario (`alpha`)\n",
        "- Balance entre descubrimiento y relevancia de la recomendación\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_hybrid(user, data_train, k=10, alpha=0.5):\n",
        "    \"\"\"\n",
        "    Genera recomendaciones híbridas para un usuario basado en popularidad y género preferido.\n",
        "\n",
        "    Args:\n",
        "        user: ID del usuario para quien se generan las recomendaciones.\n",
        "        data_train: DataFrame de entrenamiento con las columnas: userId, movieId, title, relevant_relevant_genre.\n",
        "        k: Número de recomendaciones a retornar.\n",
        "        alpha: Peso entre popularidad (1-alpha) y preferencia de género (alpha).\n",
        "\n",
        "    Returns:\n",
        "        Lista de títulos de películas recomendadas.\n",
        "    \"\"\"\n",
        "    # Calcular los scores de popularidad de películas\n",
        "    popularity_scores = data_train.groupby('movieId')['userId'].count().to_dict()\n",
        "    max_popularity = max(popularity_scores.values())\n",
        "    normalized_popularity = {movie: count / max_popularity for movie, count in popularity_scores.items()}\n",
        "\n",
        "    # Obtener los géneros preferidos del usuario\n",
        "    user_movies = data_train[data_train['userId'] == user]\n",
        "    user_genres = user_movies['relevant_genre'].value_counts().to_dict()\n",
        "    total_user_movies = sum(user_genres.values())\n",
        "    preferred_user_genres = {genre: count / total_user_movies for genre, count in user_genres.items()}\n",
        "\n",
        "    # Calcular el score combinado híbrido\n",
        "    hybrid_scores = {}\n",
        "    for movie in data_train['movieId'].unique():\n",
        "        # Score de popularidad\n",
        "        movie_popularity = normalized_popularity.get(movie, 0)\n",
        "\n",
        "        # Score de género\n",
        "        movie_genre = data_train[data_train['movieId'] == movie]['relevant_genre'].iloc[0]\n",
        "        genre_score = preferred_user_genres.get(movie_genre, 0)\n",
        "\n",
        "        # Combinar Scores de popularidad y género\n",
        "        hybrid_scores[movie] = (1 - alpha) * movie_popularity + alpha * genre_score\n",
        "\n",
        "    # Filtrar las películas ya vistas por el usuario\n",
        "    user_watched = set(user_movies['movieId'])\n",
        "    hybrid_scores = {movie: score for movie, score in hybrid_scores.items() if movie not in user_watched}\n",
        "\n",
        "    # Retornar las top k películas recomendadas\n",
        "    top_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    recommended_movie_ids = [movie for movie, _ in top_recommendations[:k]]\n",
        "\n",
        "    # Obtener los títulos de las películas recomendadas\n",
        "    recommended_movies = data_train[data_train['movieId'].isin(recommended_movie_ids)]['title'].unique()\n",
        "    return list(recommended_movies)\n"
      ],
      "metadata": {
        "id": "rvp207zOlsAC"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zUO7PL1CARHb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "845f1137-809c-494c-807a-4dec15114e76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef recommend_hybrid(user, data_train, k=10, alpha=0.5):\\n    # Calcular los scores de popularidad de películas\\n    popularity_scores = data_train['movieId'].value_counts().to_dict()\\n    max_popularity = max(popularity_scores.values())\\n    normalized_popularity = {movie: count / max_popularity for movie, count in popularity_scores.items()}\\n\\n    # Obtener los géneros preferidos del usuario\\n    user_movies = data_train[data_train['userId'] == user]\\n    user_genres = defaultdict(int)\\n\\n    for _, row in user_movies.iterrows():\\n        for genre in row['genre_list']:\\n            user_genres[genre] += 1\\n\\n    # Normalizamos los géneros según las frecuencias de películas\\n    total_user_movies = sum(user_genres.values())\\n    prefered_user_genres = {genre: count / total_user_movies for genre, count in user_genres.items()}\\n\\n    # Calcular el score combinado híbrido\\n    hybrid_scores = {}\\n    for _, row in data_train.iterrows():\\n        movie = row['movieId']\\n        genres = row['genre_list']\\n\\n        # Score de popularidad\\n        movie_popularity = normalized_popularity.get(movie, 0)\\n\\n        # Score de géneros\\n        genre_score = sum(prefered_user_genres.get(genre, 0) for genre in genres)\\n\\n        # Combinar scores de popularidad y género\\n        hybrid_scores[movie] = (1 - alpha) * movie_popularity + alpha * genre_score\\n\\n    # Filtrar las películas ya vistas por el usuario\\n    user_watched = set(user_movies['movieId'])\\n    hybrid_scores = {movie: score for movie, score in hybrid_scores.items() if movie not in user_watched}\\n\\n    # Retornar las top k películas recomendadas\\n    top_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\\n    return [movie for movie, _ in top_recommendations[:k]] \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "'''\n",
        "def recommend_hybrid(user, data_train, k=10, alpha=0.5):\n",
        "    # Calcular los scores de popularidad de películas\n",
        "    popularity_scores = data_train['movieId'].value_counts().to_dict()\n",
        "    max_popularity = max(popularity_scores.values())\n",
        "    normalized_popularity = {movie: count / max_popularity for movie, count in popularity_scores.items()}\n",
        "\n",
        "    # Obtener los géneros preferidos del usuario\n",
        "    user_movies = data_train[data_train['userId'] == user]\n",
        "    user_genres = defaultdict(int)\n",
        "\n",
        "    for _, row in user_movies.iterrows():\n",
        "        for genre in row['genre_list']:\n",
        "            user_genres[genre] += 1\n",
        "\n",
        "    # Normalizamos los géneros según las frecuencias de películas\n",
        "    total_user_movies = sum(user_genres.values())\n",
        "    prefered_user_genres = {genre: count / total_user_movies for genre, count in user_genres.items()}\n",
        "\n",
        "    # Calcular el score combinado híbrido\n",
        "    hybrid_scores = {}\n",
        "    for _, row in data_train.iterrows():\n",
        "        movie = row['movieId']\n",
        "        genres = row['genre_list']\n",
        "\n",
        "        # Score de popularidad\n",
        "        movie_popularity = normalized_popularity.get(movie, 0)\n",
        "\n",
        "        # Score de géneros\n",
        "        genre_score = sum(prefered_user_genres.get(genre, 0) for genre in genres)\n",
        "\n",
        "        # Combinar scores de popularidad y género\n",
        "        hybrid_scores[movie] = (1 - alpha) * movie_popularity + alpha * genre_score\n",
        "\n",
        "    # Filtrar las películas ya vistas por el usuario\n",
        "    user_watched = set(user_movies['movieId'])\n",
        "    hybrid_scores = {movie: score for movie, score in hybrid_scores.items() if movie not in user_watched}\n",
        "\n",
        "    # Retornar las top k películas recomendadas\n",
        "    top_recommendations = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [movie for movie, _ in top_recommendations[:k]] '''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US6Y_qaNiNfu"
      },
      "source": [
        "# Calculamos Métricas:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEPdt3u5WVXr"
      },
      "source": [
        "## Metricas de Precisión\n",
        "- MAP\n",
        "- NDCG@5\n",
        "- Precision@10\n",
        "- Recall@10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "pdzLUr2bC6dN"
      },
      "outputs": [],
      "source": [
        "def calculate_map(test_data, user_recommendation, user):\n",
        "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
        "\n",
        "  # Inicializar variables\n",
        "  precision_sum = 0\n",
        "  relevant_count = 0\n",
        "\n",
        "  for i, item in enumerate(user_recommendation, start=1):\n",
        "    if item in relevant_items:\n",
        "      relevant_count += 1\n",
        "      precision_sum += relevant_count / i\n",
        "\n",
        "  if relevant_count > 0:\n",
        "    map_value = precision_sum / relevant_count\n",
        "  else:\n",
        "    map_value = 0\n",
        "\n",
        "  return map_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "7p1J8piDERMQ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def calculate_ndcg(test_data, user_recommendation, user):\n",
        "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
        "\n",
        "  # Calcular DCG e IDCG\n",
        "  dcg = 0\n",
        "  idcg = 0\n",
        "  for i, item in enumerate(user_recommendation, start=1):\n",
        "    if item in relevant_items:\n",
        "      dcg += 1 / math.log2(i + 1)\n",
        "    idcg += 1 / math.log2(i + 1)\n",
        "\n",
        "  # Calcular NDCG\n",
        "  if idcg > 0:\n",
        "    ndcg_value = dcg / idcg\n",
        "  else:\n",
        "    ndcg_value = 0\n",
        "\n",
        "  return ndcg_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "0YV8xhO-aLPG"
      },
      "outputs": [],
      "source": [
        "def calculate_precision_at_k(test_data, user_recommendation, user):\n",
        "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
        "\n",
        "  relevant_count = 0\n",
        "  for item in user_recommendation:\n",
        "    if item in relevant_items:\n",
        "      relevant_count += 1\n",
        "\n",
        "  precision_at_k = relevant_count / len(user_recommendation)\n",
        "\n",
        "  return precision_at_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1n6oA1mzacnn"
      },
      "outputs": [],
      "source": [
        "def calculate_recall_at_k(test_data, user_recommendation, user):\n",
        "  relevant_items = test_data[test_data['userId'] == user]['movieId'].tolist()\n",
        "\n",
        "  relevant_count = 0\n",
        "  for item in user_recommendation:\n",
        "    if item in relevant_items:\n",
        "      relevant_count += 1\n",
        "\n",
        "  recall_at_k = relevant_count / len(relevant_items)\n",
        "\n",
        "  return recall_at_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c3T-7RzWcS6"
      },
      "source": [
        "\n",
        "## Métricas de Diversidad: ¡Enfoque del Estudio!\n",
        "- **User Diversity**: Métrica propuesta por la investigación\n",
        "- Long Tail\n",
        "- Shannon Entropy\n",
        "- Intra List Diversity\n",
        "- Diversity Coverage\n",
        "- Inverse Propensity Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYfcGlSqJcMK"
      },
      "source": [
        "### Definición de **USER DIVERSITY**, la métrica de la investigación.\n",
        "1. `UD = 1 - (|∑{j=1...k}[(R_j/R)*log(R_j/R)]| / log(k))`\n",
        "2. `k`: número de categorías para un usuario.\n",
        "3. `R`: número total de recomendaciones.\n",
        "4. `(R_j/R)`: Proporción de recomendaciones del usuario que pertenecen a la categoría `j`\n",
        "5. `log(...)`: para penalizar concentración excesiva en una sola categoría.\n",
        "6. `/ log(k)`: normaliza el valor.\n",
        "7. `1 - `: Valor resultante entre 0 y 1.\n",
        "8. *Valor alto*: alta diversidad en las recomendaciones recibidas por el usuario (pertenecen a varias categorías favoritas)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculate_user_diversity(user_top_categories, user_recommendation, user_id, k=5):\n",
        "    # Obtener las top k categorías del usuario\n",
        "    categories_user = user_top_categories[user_top_categories['userId'] == user_id]['relevant_genre'].tolist()[:k]\n",
        "\n",
        "    # Filtrar recomendaciones para géneros relevantes\n",
        "    filtered_recommendations = [\n",
        "        rec for rec in user_recommendation\n",
        "        if rec in movies_data[movies_data['relevant_genre'].isin(categories_user)]['movieId'].tolist()\n",
        "    ]\n",
        "\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(filtered_recommendations)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\n",
        "\n",
        "    # Filtrar datos de movies para las peliculas recomendadas relevantes\n",
        "    filtered_data = movies_data[movies_data['movieId'].isin(filtered_recommendations)]\n",
        "\n",
        "    # Calcular sum_diversity\n",
        "    sum_diversity = 0\n",
        "    for genre in categories_user:\n",
        "        recommended_movies_genre = filtered_data[filtered_data['relevant_genre'] == genre]\n",
        "        r_j = len(recommended_movies_genre)\n",
        "\n",
        "        if r_j > 0:\n",
        "            proportion = r_j / r\n",
        "            contribution = proportion * math.log(proportion)\n",
        "            sum_diversity += contribution\n",
        "\n",
        "    # Normalizar con log(k)\n",
        "    max_diversity = math.log(k) if k > 1 else 1.0\n",
        "    # Ponemos en valor absoluto sum_diversity\n",
        "    sum_diversity = abs(sum_diversity)\n",
        "\n",
        "    if max_diversity == 0:\n",
        "        return 0.0  # Si k <= 1, diversidad no tiene sentido\n",
        "\n",
        "    # Calcular diversidad final\n",
        "    diversity = 1 - (sum_diversity / max_diversity)\n",
        "\n",
        "    # Depuración adicional\n",
        "    return diversity\n"
      ],
      "metadata": {
        "id": "BwA1HtYxmY6c"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GFRa6xoowmqk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "ff092a3a-2eb3-4967-f114-7a2544014900"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" import math\\n\\ndef calculate_user_diversity(user_top_categories, user_recommendation, user_id, k=5):\\n    # Obtener las top k categorías del usuario\\n    categories_user = user_top_categories[user_top_categories['userId'] == user_id]['relevant_genre'].tolist()[:k]\\n\\n    # Filtrar recomendaciones para géneros relevantes\\n    filtered_recommendations = []\\n    for rec in user_recommendation:\\n      genre_list = movies.copy()\\n      genre_list = genre_list[genre_list['movieId'] == rec]\\n      genre_list['genres_list'] = genre_list['genres'].str.split('|')\\n      genre_list = genre_list['genres_list'].tolist()\\n      genre_list_total = []\\n      for genre in genre_list:\\n        genre_list_total.extend(genre)\\n      if rec in genre_list_total:\\n        filtered_recommendations.append(rec)\\n\\n\\n    # Total de recomendaciones relevantes\\n    r = len(filtered_recommendations)\\n    if r == 0:\\n        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\\n\\n    # Filtrar datos de movie para las peliculas recomendadas relevantes\\n    filtered_data = data_movie[data_movie['movieId'].isin(filtered_recommendations)]\\n\\n    # Calcular sum_diversity\\n    sum_diversity = 0\\n    for genre in categories_user:\\n        recommended_movie_genre = filtered_data[filtered_data['genre_list'].apply(lambda x: genre in x)]['movieId'].tolist()\\n        r_j = len(recommended_movie_genre)\\n\\n        if r_j > 0:\\n            proportion = r_j / r\\n            contribution = proportion * math.log(proportion)\\n            sum_diversity += contribution\\n\\n    # Normalizar con log(k)\\n    max_diversity = math.log(k) if k > 1 else 1.0\\n    # Ponemos en valor absoluto sum_diversity\\n    sum_diversity = abs(sum_diversity)\\n\\n    if max_diversity == 0:\\n        return 0.0  # Si k <= 1, diversidad no tiene sentido\\n\\n    # Calcular diversidad final\\n    diversity = 1 - (sum_diversity / max_diversity)\\n\\n    # Depuración adicional\\n    return diversity\\n \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "''' import math\n",
        "\n",
        "def calculate_user_diversity(user_top_categories, user_recommendation, user_id, k=5):\n",
        "    # Obtener las top k categorías del usuario\n",
        "    categories_user = user_top_categories[user_top_categories['userId'] == user_id]['relevant_genre'].tolist()[:k]\n",
        "\n",
        "    # Filtrar recomendaciones para géneros relevantes\n",
        "    filtered_recommendations = []\n",
        "    for rec in user_recommendation:\n",
        "      genre_list = movies.copy()\n",
        "      genre_list = genre_list[genre_list['movieId'] == rec]\n",
        "      genre_list['genres_list'] = genre_list['genres'].str.split('|')\n",
        "      genre_list = genre_list['genres_list'].tolist()\n",
        "      genre_list_total = []\n",
        "      for genre in genre_list:\n",
        "        genre_list_total.extend(genre)\n",
        "      if rec in genre_list_total:\n",
        "        filtered_recommendations.append(rec)\n",
        "\n",
        "\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(filtered_recommendations)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\n",
        "\n",
        "    # Filtrar datos de movie para las peliculas recomendadas relevantes\n",
        "    filtered_data = data_movie[data_movie['movieId'].isin(filtered_recommendations)]\n",
        "\n",
        "    # Calcular sum_diversity\n",
        "    sum_diversity = 0\n",
        "    for genre in categories_user:\n",
        "        recommended_movie_genre = filtered_data[filtered_data['genre_list'].apply(lambda x: genre in x)]['movieId'].tolist()\n",
        "        r_j = len(recommended_movie_genre)\n",
        "\n",
        "        if r_j > 0:\n",
        "            proportion = r_j / r\n",
        "            contribution = proportion * math.log(proportion)\n",
        "            sum_diversity += contribution\n",
        "\n",
        "    # Normalizar con log(k)\n",
        "    max_diversity = math.log(k) if k > 1 else 1.0\n",
        "    # Ponemos en valor absoluto sum_diversity\n",
        "    sum_diversity = abs(sum_diversity)\n",
        "\n",
        "    if max_diversity == 0:\n",
        "        return 0.0  # Si k <= 1, diversidad no tiene sentido\n",
        "\n",
        "    # Calcular diversidad final\n",
        "    diversity = 1 - (sum_diversity / max_diversity)\n",
        "\n",
        "    # Depuración adicional\n",
        "    return diversity\n",
        " '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZEaHnChqo0j"
      },
      "source": [
        "### **Long Tail**:\n",
        "Mide que tan diversas son las recomendaciones en términos de popularidad de los items.\n",
        "1.  Equación: `LT = |Intersection(Rec, TailItems)| / |Rec|`\n",
        "2. Parametro `beta=0.4`: define umbral para considerar item como parte de la cola larga.\n",
        "3. *Valor alto*: se recomiendan más items poco populares\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "JSxWcIUbJ1Ux"
      },
      "outputs": [],
      "source": [
        "def calculate_long_tail(test_data, user_recommendation, user_id, beta_value=0.5):\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(user_recommendation)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones relevantes, diversidad es 0.\n",
        "\n",
        "    # Procesamos las recomendaciones para obtener la popularidad de los items:\n",
        "    item_popularity = test_data['movieId'].value_counts().to_dict()\n",
        "\n",
        "    # Ordenamos los items por popularidad\n",
        "    sorted_items = sorted(item_popularity.items(), key=lambda x: x[1], reverse=True)\n",
        "    n_items = len(sorted_items)\n",
        "    tail_max = int(beta_value * n_items)\n",
        "\n",
        "    # Identificamos los items en la LT\n",
        "    long_tail = set(item for item, _ in sorted_items[tail_max:])\n",
        "\n",
        "    # Calculamos la proporcion de items recomendades nen la cola larga\n",
        "    longtail_recommendation = sum(1 for item in user_recommendation if item in long_tail)\n",
        "\n",
        "    return longtail_recommendation / r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmJOSk-xqs_J"
      },
      "source": [
        "### **Entropía de Shannon**:\n",
        "Mide la incertidumbre o aleatoriedad de la distribución de recomendaciones.\n",
        "1. `H = -∑(pi*log2(pi)) / log2(n)`\n",
        "2. `pi`: probabilidad de cada item en las recomendaciones\n",
        "3. *Valor alto*: mayor aleatoriedad/diversidad en las recomendaciones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "tugWz76tKi9-"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def calculate_shannon_entropy(test_data, user_recommendation, user_id):\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(user_recommendation)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones, entropía es 0.\n",
        "\n",
        "    # Obtener géneros de las películas recomendadas\n",
        "    rec_genres = []\n",
        "    for rec in user_recommendation:\n",
        "        movie_genres = test_data[test_data['movieId'] == rec]['relevant_genre']\n",
        "        if not movie_genres.empty:\n",
        "            rec_genres.extend(movie_genres.iloc[0])  # Añadir los géneros de la película\n",
        "\n",
        "    # Si no hay géneros recomendados, devolver 0\n",
        "    if len(rec_genres) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Contar la frecuencia de cada género\n",
        "    genre_counts = {genre: rec_genres.count(genre) for genre in set(rec_genres)}\n",
        "    frequencies = [count / r for count in genre_counts.values()]\n",
        "\n",
        "    # Calcular la entropía\n",
        "    entropy = -sum(p * math.log(p, 2) for p in frequencies if p > 0)\n",
        "\n",
        "    # Normalizar con log(r)\n",
        "    max_entropy = math.log(r, 2) if r > 1 else 1.0\n",
        "    entropy /= max_entropy\n",
        "\n",
        "    return entropy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9KGJFp8qwYp"
      },
      "source": [
        "### **Intra List Diversity**:\n",
        "Calcula diversidad basándose en la similitud entre los items.\n",
        "1. `ILD = ∑∑(d(i,j)) / (n*(n-1)/2)`\n",
        "2. `d(i,j)`: es la distancia entre los items `i` y `j`, usando coseno\n",
        "3. *Valor alto*: mayor diversidad entre los items recomendados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "WVFAJiK5K58R"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_intra_list_diversity(test_data, user_recommendation, user_id):\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(user_recommendation)\n",
        "    if r < 2:\n",
        "        return 0.0  # Diversidad no se puede calcular con menos de 2 recomendaciones\n",
        "\n",
        "    # Crear one-hot encoding de características basadas en géneros\n",
        "    unique_genres = set(genre for genres in test_data['relevant_genre'] for genre in genres)\n",
        "    genre_to_index = {genre: idx for idx, genre in enumerate(unique_genres)}\n",
        "\n",
        "    # Crear vectores one-hot para cada película recomendada\n",
        "    genre_vectors = []\n",
        "    for movie_id in user_recommendation:\n",
        "        movie_data = test_data[test_data['movieId'] == movie_id]\n",
        "        if not movie_data.empty:\n",
        "            genres = movie_data.iloc[0]['relevant_genre']\n",
        "            one_hot = [1 if genre_to_index[genre] in [genre_to_index[g] for g in genres] else 0\n",
        "                       for genre in unique_genres]\n",
        "            genre_vectors.append(one_hot)\n",
        "\n",
        "    # Si no hay recomendaciones relevantes, devolver 0\n",
        "    if len(genre_vectors) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # Convertir los vectores a una matriz\n",
        "    feature_vectors = np.array(genre_vectors)\n",
        "\n",
        "    # Calcular matriz de similitud usando producto punto\n",
        "    similarity_matrix = np.dot(feature_vectors, feature_vectors.T)\n",
        "    n = len(feature_vectors)\n",
        "\n",
        "    # Calcular la diversidad intra-lista como la distancia coseno promedio\n",
        "    total_similarity = np.sum(similarity_matrix) - np.sum(np.diag(similarity_matrix))\n",
        "    comparisons = n * (n - 1)  # Total de pares únicos\n",
        "    intra_list_diversity = 1 - (total_similarity / comparisons)\n",
        "\n",
        "    return intra_list_diversity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deRuDWKOq0yr"
      },
      "source": [
        "### **Diversity Coverage**:\n",
        "Mide la cobertura como la proporción de items únicos recomendados respceto al total de items posibles.\n",
        "1. `DC = |Unique_Rec| / |All Items|`\n",
        "2. *Valor alto*: se están recomendando items de todo el catálogo\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "FwVhP8vNLGPb"
      },
      "outputs": [],
      "source": [
        "def calculate_diversity_coverage(test_data, user_recommendation, user_id):\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(user_recommendation)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones, cobertura es 0.\n",
        "\n",
        "    # Obtener géneros únicos de las películas recomendadas\n",
        "    rec_genres = set()\n",
        "    for rec in user_recommendation:\n",
        "        movie_data = test_data[test_data['movieId'] == rec]\n",
        "        if not movie_data.empty:\n",
        "            rec_genres.update(movie_data.iloc[0]['relevant_genre'])\n",
        "\n",
        "    # Si no hay géneros recomendados, devolver 0\n",
        "    if len(rec_genres) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    # Obtener todos los posibles géneros\n",
        "    all_genres = set(genre for genres in test_data['relevant_genre'] for genre in genres)\n",
        "\n",
        "    # Calcular la cobertura de la diversidad\n",
        "    diversity_coverage = len(rec_genres) / len(all_genres)\n",
        "\n",
        "    return diversity_coverage\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuETWeMJq3NL"
      },
      "source": [
        "### **Inverse Propensity Score** (IPS):\n",
        "Penaliza la recomendación de items muy populares\n",
        "1. `IPS = (1/p(i))`\n",
        "2. Parametro `lambda` para suavizar la propensidad\n",
        "3. `p(i)`: probabilidad que el item `i` sea seleccionado\n",
        "4. *Valor alto*: se están recomendando más items poco probables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "3Ec92UgBXkMX"
      },
      "outputs": [],
      "source": [
        "def calculate_inverse_propensity_score(test_data, user_recommendation, user_id, lambda_value=0.5):\n",
        "    # Total de recomendaciones relevantes\n",
        "    r = len(user_recommendation)\n",
        "    if r == 0:\n",
        "        return 0.0  # Si no hay recomendaciones, el IPS es 0.\n",
        "\n",
        "    # Calcular la popularidad de las películas\n",
        "    movie_popularity = test_data['movieId'].value_counts().to_dict()\n",
        "    interaction_count = sum(movie_popularity.values())\n",
        "\n",
        "    # Calcular Propensity Score\n",
        "    prop_score = {\n",
        "        movie: ((movie_popularity.get(movie, 0) + lambda_value) / (interaction_count + lambda_value))\n",
        "        for movie in test_data['movieId'].unique()\n",
        "    }\n",
        "\n",
        "    # Calcular el IPS promedio\n",
        "    ips = [1 / prop_score[movie] for movie in user_recommendation if movie in prop_score]\n",
        "    if len(ips) > 0:\n",
        "        ips_avg = sum(ips) / len(ips)\n",
        "        return ips_avg\n",
        "    else:\n",
        "        return 0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqwU42k6icty"
      },
      "source": [
        "# Ejecución Método Most Popular. PROBAR: Random y Collaborative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLh-GFiMwFMB"
      },
      "source": [
        "Creamos una función para ejecutar el modelo con parametros modificables correspondientes a:\n",
        "- `test_data`: Datos para testeo del modelo\n",
        "- `train_data`: Datos para entrenamiento del modelo\n",
        "- `top_n`: Para recommendación *Most Popular*\n",
        "- `k`: Cuantos clusters de géneros se considerarán para los usuarios\n",
        "- `beta_lt`: Parametro beta de métrica *Long Tail*, define umbral para considerar un item como parte de la *Long Tail*\n",
        "- `lambda_ips`: Parámetro de métrica *Inverse Propensity Score*, sirve para suavizar el resultado.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "fvZHOLECFVhb"
      },
      "outputs": [],
      "source": [
        "def most_popular_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "\n",
        "  for userid in test_data['userId'].unique():\n",
        "\n",
        "    recommend_list = recommend_most_popular(userid, train_data, top_n)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wHcux_JRJjE"
      },
      "source": [
        "# Ejecución Método Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "wFyUHSuVRJTu"
      },
      "outputs": [],
      "source": [
        "def random_metrcis(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "\n",
        "  for userid in test_data['userId'].unique():\n",
        "\n",
        "    recommend_list = recommend_random(userid, train_data, top_n)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIv6m1ndTAt3"
      },
      "source": [
        "# Ejecución de método IKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "nNyNGhqmTGT6"
      },
      "outputs": [],
      "source": [
        "def IKNN_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "\n",
        "  for userid in test_data['userId'].unique():\n",
        "    model = MovieIKNN(k=20)\n",
        "    model.fit(train_data)\n",
        "\n",
        "    recommend_list = model.recommend(userid, train_data, top_n)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecución de metodo deepFM"
      ],
      "metadata": {
        "id": "f8Rl00gkq6dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def deepfm_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "  for userid in test_data['userId'].unique():\n",
        "    recommend_list = recommend_deepfm(userid, train_data, top_n)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ],
      "metadata": {
        "id": "5FHi9UVZq-qv"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejecución de método FastFM"
      ],
      "metadata": {
        "id": "zNC-V749ralp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fastfm_metrics(test_data, train_data, top_n, k, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "  for userid in test_data['userId'].unique():\n",
        "    recommend_list = recommend_fastfm(userid, train_data, top_n)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ],
      "metadata": {
        "id": "wgYRjUJmrj0s"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j9JMlI1Won2"
      },
      "source": [
        "# Ejecución de método hibrido"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "weIgdZN-YQkK"
      },
      "outputs": [],
      "source": [
        "def hybrid_metrics(test_data, train_data, top_n, k, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5):\n",
        "  map_sum = 0\n",
        "  ndcg_sum = 0\n",
        "  precision_sum = 0\n",
        "  recall_sum = 0\n",
        "  diversity_sum = 0\n",
        "  lt_sum = 0\n",
        "  entropy_sum = 0\n",
        "  ild_sum = 0\n",
        "  dc_sum = 0\n",
        "  ips_sum = 0\n",
        "  user_count = 0\n",
        "\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "\n",
        "  for userid in test_data['userId'].unique():\n",
        "\n",
        "    recommend_list = recommend_hybrid(userid, train_data, top_n, alpha_hybrid)\n",
        "\n",
        "    #print(f\"User: {userid} - Recommended: {recommend_list}\")\n",
        "\n",
        "    # Calcular Map y nDCG y User Diversity\n",
        "    map_user = calculate_map(test_data, recommend_list, userid)\n",
        "    ndcg_user = calculate_ndcg(test_data, recommend_list, userid)\n",
        "    precision_user = calculate_precision_at_k(test_data, recommend_list, userid)\n",
        "    recall_user = calculate_recall_at_k(test_data, recommend_list, userid)\n",
        "    diversity_user = calculate_user_diversity(top_k_categories_data, recommend_list, userid)\n",
        "    lt_user = calculate_long_tail(test_data, recommend_list, userid, beta_lt)\n",
        "    entropy_user = calculate_shannon_entropy(test_data, recommend_list, userid)\n",
        "    ild_user = calculate_intra_list_diversity(test_data, recommend_list, userid)\n",
        "    dc_user = calculate_diversity_coverage(test_data, recommend_list, userid)\n",
        "    ips_user = calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "\n",
        "    map_sum += map_user\n",
        "    ndcg_sum += ndcg_user\n",
        "    precision_sum += precision_user\n",
        "    recall_sum += recall_user\n",
        "    diversity_sum += diversity_user\n",
        "    lt_sum += lt_user\n",
        "    entropy_sum += entropy_user\n",
        "    ild_sum += ild_user\n",
        "    dc_sum += dc_user\n",
        "    ips_sum += ips_user\n",
        "    user_count += 1\n",
        "\n",
        "  # Promedio de métricas\n",
        "  map_avg = map_sum / user_count\n",
        "  ndcg_avg = ndcg_sum / user_count\n",
        "  precision_avg = precision_sum / user_count\n",
        "  recall_avg = recall_sum / user_count\n",
        "  diversity_avg = diversity_sum / user_count\n",
        "  lt_avg = lt_sum / user_count\n",
        "  entropy_avg = entropy_sum / user_count\n",
        "  ild_avg = ild_sum / user_count\n",
        "  dc_avg = dc_sum / user_count\n",
        "  ips_avg = ips_sum / user_count\n",
        "\n",
        "  return {\n",
        "      \"MAP\": map_avg,\n",
        "      \"nDCG\": ndcg_avg,\n",
        "      \"Precision\": precision_avg,\n",
        "      \"Recall\": recall_avg,\n",
        "      \"User_Diversity\": diversity_avg,\n",
        "      \"Long_Tail\": lt_avg,\n",
        "      \"Shannon_Entropy\": entropy_avg,\n",
        "      \"Intra_List_Diversity\": ild_avg,\n",
        "      \"Diversity_Coverage\": dc_avg,\n",
        "      \"Inverse_Propensity_Score\": ips_avg\n",
        "  }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg-8ejrrx2Ih"
      },
      "source": [
        "## Ejecución y obtención de métricas\n",
        "\n",
        "### Metodo Most Popular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t_lsMr2BGx2D"
      },
      "outputs": [],
      "source": [
        "metric_results = most_popular_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results['MAP']}\")\n",
        "print(f\"nDCG: {metric_results['nDCG']}\")\n",
        "print(f\"Precision: {metric_results['Precision']}\")\n",
        "print(f\"Recall: {metric_results['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results['Inverse_Propensity_Score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s55XJxjlRxIJ"
      },
      "source": [
        "### Método Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjJPRu_rRu-Y"
      },
      "outputs": [],
      "source": [
        "metric_results_random = random_metrcis(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results_random['MAP']}\")\n",
        "print(f\"nDCG: {metric_results_random['nDCG']}\")\n",
        "print(f\"Precision: {metric_results_random['Precision']}\")\n",
        "print(f\"Recall: {metric_results_random['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results_random['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results_random['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results_random['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results_random['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results_random['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results_random['Inverse_Propensity_Score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdAdycuzSr4h"
      },
      "source": [
        "Método IKNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5zSjSBoSqPm"
      },
      "outputs": [],
      "source": [
        "metric_results_iknn = IKNN_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results_iknn['MAP']}\")\n",
        "print(f\"nDCG: {metric_results_iknn['nDCG']}\")\n",
        "print(f\"Precision: {metric_results_iknn['Precision']}\")\n",
        "print(f\"Recall: {metric_results_iknn['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results_iknn['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results_iknn['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results_iknn['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results_iknn['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results_iknn['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results_iknn['Inverse_Propensity_Score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método Deep FM"
      ],
      "metadata": {
        "id": "wzg1VHemsEbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_results_deepfm = deepfm_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results_deepfm['MAP']}\")\n",
        "print(f\"nDCG: {metric_results_deepfm['nDCG']}\")\n",
        "print(f\"Precision: {metric_results_deepfm['Precision']}\")\n",
        "print(f\"Recall: {metric_results_deepfm['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results_deepfm['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results_deepfm['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results_deepfm['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results_deepfm['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results_deepfm['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results_deepfm['Inverse_Propensity_Score']}\")"
      ],
      "metadata": {
        "id": "49Gm_MfMsHyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método Fast FM"
      ],
      "metadata": {
        "id": "muHf7ivKsNXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric_results_fastfm = fastfm_metrics(data_movie_test, data_movie_train, 10, 5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results_fastfm['MAP']}\")\n",
        "print(f\"nDCG: {metric_results_fastfm['nDCG']}\")\n",
        "print(f\"Precision: {metric_results_fastfm['Precision']}\")\n",
        "print(f\"Recall: {metric_results_fastfm['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results_fastfm['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results_fastfm['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results_fastfm['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results_fastfm['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results_fastfm['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results_fastfm['Inverse_Propensity_Score']}\")"
      ],
      "metadata": {
        "id": "PypSxPrTsP_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Método Hybrid"
      ],
      "metadata": {
        "id": "jyF5FB1dsA3e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrHLjXrKYsgq"
      },
      "outputs": [],
      "source": [
        "metric_results_hybrid = hybrid_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
        "print(f\"MAP: {metric_results_hybrid['MAP']}\")\n",
        "print(f\"nDCG: {metric_results_hybrid['nDCG']}\")\n",
        "print(f\"Precision: {metric_results_hybrid['Precision']}\")\n",
        "print(f\"Recall: {metric_results_hybrid['Recall']}\")\n",
        "print(f\"User_Diversity: {metric_results_hybrid['User_Diversity']}\")\n",
        "print(f\"Long_Tail: {metric_results_hybrid['Long_Tail']}\")\n",
        "print(f\"Shannon_Entropy: {metric_results_hybrid['Shannon_Entropy']}\")\n",
        "print(f\"Intra_List_Diversity: {metric_results_hybrid['Intra_List_Diversity']}\")\n",
        "print(f\"Diversity_Coverage: {metric_results_hybrid['Diversity_Coverage']}\")\n",
        "print(f\"Inverse_Propensity_Score: {metric_results_hybrid['Inverse_Propensity_Score']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXG_QtaQGLBg"
      },
      "source": [
        "# Ejecución Global de Métodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLOqxW5XFtEn"
      },
      "outputs": [],
      "source": [
        "def global_metrics(test_data, train_data, top_n, k, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5):\n",
        "  model_iknn = MovieIKNN(k=20)\n",
        "  model_iknn.fit(train_data)\n",
        "\n",
        "  # Arreglo para almacenar los resultados de cada metodo\n",
        "  records = []\n",
        "\n",
        "  # Obtenemos las top k categorias\n",
        "  top_k_categories_data = get_top_k_categories(test_data, k)\n",
        "\n",
        "  for userid in test_data['user_id'].unique():\n",
        "    # Genero recomendaciones para cada modelo\n",
        "    recommendations = {\n",
        "        'most_popular': recommend_most_popular(userid, train_data, top_n),\n",
        "        'random': recommend_random(userid, train_data, top_n),\n",
        "        'iknn': model_iknn.recommend(userid, train_data, top_n),\n",
        "        'fastfm': recommend_fastfm(userid, train_data, top_n),\n",
        "        'deepfm': recommend_deepfm(userid, train_data, top_n),\n",
        "        'hybrid': recommend_hybrid(userid, train_data, top_n, alpha_hybrid)\n",
        "    }\n",
        "\n",
        "    # Calcular Metricas para cada modelo\n",
        "    for model, recommend_list in recommendations.items():\n",
        "      record = {\n",
        "        'user_id': userid,\n",
        "        'model': model,\n",
        "          # Metricas de precision\n",
        "        'MAP': calculate_map(test_data, recommend_list, userid),\n",
        "        'nDCG': calculate_ndcg(test_data, recommend_list, userid),\n",
        "        'Precision': calculate_precision_at_k(test_data, recommend_list, userid),\n",
        "        'Recall': calculate_recall_at_k(test_data, recommend_list, userid),\n",
        "          # Metricas de diversidad\n",
        "        'User_Diversity': calculate_user_diversity(top_k_categories_data, recommend_list, userid),\n",
        "        'Long_Tail': calculate_long_tail(test_data, recommend_list, userid, beta_lt),\n",
        "        'Shannon_Entropy': calculate_shannon_entropy(test_data, recommend_list, userid),\n",
        "        'Intra_List_Diversity': calculate_intra_list_diversity(test_data, recommend_list, userid),\n",
        "        'Diversity_Coverage': calculate_diversity_coverage(test_data, recommend_list, userid),\n",
        "        'Inverse_Propensity_Score': calculate_inverse_propensity_score(test_data, recommend_list, userid, lambda_ips)\n",
        "      }\n",
        "      records.append(record)\n",
        "\n",
        "  # Promedio de métricas\n",
        "  results_df = pd.DataFrame(records)\n",
        "  #print(results_df.head())\n",
        "\n",
        "  return results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I7-QL9RlFOA"
      },
      "outputs": [],
      "source": [
        "results_df = global_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV6yMeEWJTnz"
      },
      "source": [
        "## Analisis Global de Metricas\n",
        "Analiza y visualiza los resultados de las métricas globales usando el Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s60mg3IVLBaz"
      },
      "source": [
        "### Generar visualizaciones comparativas entre los modelos\n",
        "Creamos 3 tipos de gráficos para las visualizaciones:\n",
        "1. Gráfico de cajas para cada métrica mostrando su distribución.\n",
        "2. Heatmap de correlaciones entre métricas.\n",
        "3. Gráfico de radar para comparar modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vUA1EbSK0UL"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_global_metrics(results_df):\n",
        "  metrics = ['MAP', 'nDCG', 'Precision', 'Recall' , 'User_Diversity', 'Long_Tail', 'Shannon_Entropy', 'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
        "\n",
        "  # Configurar el estilo usando seaborn\n",
        "  sns.set_style\n",
        "\n",
        "  # Crear el gráfico de cajas para cada metrica\n",
        "  fig, axes = plt.subplots(3, 4, figsize=(20, 10))\n",
        "  fig.suptitle('Distribución de Métricas por Modelo', fontsize=16)\n",
        "\n",
        "  for i, metric in enumerate(metrics):\n",
        "    row = i // 4\n",
        "    col = i % 4\n",
        "    ax = axes[row, col]\n",
        "    sns.boxplot(x='model', y=metric, data=results_df, ax=axes[row, col])\n",
        "    axes[row, col].set_xticklabels(axes[row, col].get_xticklabels(), rotation=45)\n",
        "    ax.set_title(metric)\n",
        "    ax.set_xlabel('Modelo')\n",
        "    ax.set_ylabel(metric)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  # Generar heatmap de correlaciones entre métricas\n",
        "  correlation_matrix = results_df[metrics].corr()\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "  plt.title('Correlación entre Métricas')\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "  # Grafico de radar para comparar modelos\n",
        "    # Calcular promedios de las metricas normalizados\n",
        "  avg_metrics = results_df.groupby('model')[metrics].mean()\n",
        "  normalized_metrics = (avg_metrics - avg_metrics.min()) / (avg_metrics.max() - avg_metrics.min())\n",
        "\n",
        "    # Configuramos grafico de radar: https://plotly.com/python/radar-chart/\n",
        "  fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))\n",
        "  angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)\n",
        "  angles = np.concatenate((angles, [angles[0]]))\n",
        "\n",
        "    # Graficamos las metricas\n",
        "  for model in normalized_metrics.index:\n",
        "    values = np.concatenate((normalized_metrics.loc[model], [normalized_metrics.loc[model][0]]))\n",
        "    ax.plot(angles, values, 'o-', linewidth=2, label=model)\n",
        "    ax.fill(angles, values, alpha=0.25)\n",
        "\n",
        "    # Configuramos etiquetas\n",
        "  ax.set_xticks(angles[:-1], metrics)\n",
        "  ax.set_ylim(0, 1)\n",
        "  plt.legend(loc='best', bbox_to_anchor=(0.5, -0.05))\n",
        "  plt.title('Comparación de Métodos según Métricas Normalizadas')\n",
        "  # plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKEERnLFOiKx"
      },
      "source": [
        "### Generar Análisis Estadístico de Significancia\n",
        "Realiza un análisis estadístico de las diferencias entre modelos, incluyendo:\n",
        "1. Media y desviación estándar por modelo.\n",
        "2. Test ANOVA para evaluar la significancia estadística\n",
        "3. Correlaciones entre las métricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKD6N9-KO6ZR"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "def analyze_significance(results_df):\n",
        "  metrics = ['MAP', 'nDCG', 'Precision', 'Recall', 'User_Diversity', 'Long_Tail', 'Shannon_Entropy', 'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
        "  # Calcular promedios de las metricas\n",
        "  avg_metrics = results_df.groupby('model').mean()\n",
        "  print(\"Promedios de Métricas por modelo:\")\n",
        "  print(avg_metrics.round(4))\n",
        "\n",
        "  # Calcular desviaciones estandar\n",
        "  std_metrics = results_df.groupby('model').std()\n",
        "  print(\"Desviaciones estandar de Métricas por modelo:\")\n",
        "  print(std_metrics.round(4))\n",
        "\n",
        "  # Calcular Test de ANOVA\n",
        "  # Generamos grupos de comparacion segun modelos\n",
        "  anova_results = {}\n",
        "  for metric in metrics:\n",
        "    groups = [group for _, group in results_df.groupby('model')[metric]]\n",
        "    f_value, p_value = stats.f_oneway(*groups)\n",
        "    anova_results[metric] = {'Estadistico-F': f_value, 'Valor-P': p_value}\n",
        "\n",
        "  # Creo un dataframe con los resultados\n",
        "  anova_df = pd.DataFrame(anova_results).T\n",
        "  print(\"Resultados ANOVA:\")\n",
        "  print(anova_df.round(4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fKTMoDKKySz"
      },
      "source": [
        "## Generar Resultados Finales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QriJxcsrJaPW"
      },
      "outputs": [],
      "source": [
        "def analyze_global_metrics(results_df):\n",
        "  # Preparar e imprimir las visualizaciones usando nuestra funcion\n",
        "  visualize_global_metrics(results_df)\n",
        "\n",
        "  # Analisis estadistico usando nuestra funcion\n",
        "  analyze_significance(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB8s_k35QMed"
      },
      "source": [
        "### **FALTA POR IMPLEMENTAR**: Testeo de Parámetros para Ejecución Global\n",
        "Queda ejecutado con parámetros:\n",
        "- top_n = 10\n",
        "- k = 5\n",
        "- alpha_hybrid=0.5\n",
        "- beta_lt=0.4\n",
        "- lambda_ips=0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbDirXKWRmat"
      },
      "outputs": [],
      "source": [
        "# Obtener dataframe de resultados\n",
        "results_df = global_metrics(data_movie_test, data_movie_train, 10, 5, alpha_hybrid=0.5, beta_lt=0.4, lambda_ips=0.5)\n",
        "\n",
        "# Analisis estadistico usando nuestra funcion\n",
        "analyze_global_metrics(results_df)\n",
        "\n",
        "# Guardar dataframe de resultados\n",
        "results_df.to_csv('global_metrics_results.csv', index=False)\n",
        "print(\"DataFrame de resultados guardado en 'global_metrics_results.csv'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCcyp5g0fQeL"
      },
      "source": [
        "Graficar ahora con distintos `top_n`para ver como se comportan las metricas de los distintos modelos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leb3IjW-orbg"
      },
      "outputs": [],
      "source": [
        "# Actualización de los modelos\n",
        "models = ['most_popular', 'iknn', 'hybrid', 'random']\n",
        "metrics = ['MAP', 'nDCG', 'Precision', 'Recall', 'User_Diversity', 'Long_Tail', 'Shannon_Entropy',\n",
        "           'Intra_List_Diversity', 'Diversity_Coverage', 'Inverse_Propensity_Score']\n",
        "top_n_list = [5, 10, 15, 20, 25]\n",
        "k_category_list = [3, 5, 7]\n",
        "\n",
        "# Crear datos simulados nuevamente para incluir los modelos actualizados\n",
        "data = []\n",
        "for model in models:\n",
        "    for k in k_category_list:\n",
        "        for top_n in top_n_list:\n",
        "            values = np.random.rand(len(metrics))\n",
        "            data.append([model, k, top_n] + list(values))\n",
        "\n",
        "# Crear DataFrame actualizado\n",
        "columns = ['model', 'k', 'top_n'] + metrics\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Crear figura con filas como k y columnas como métricas\n",
        "fig, axes = plt.subplots(len(k_category_list), len(metrics), figsize=(40, 12), sharex=True, sharey=False)\n",
        "fig.suptitle(\"Metrics across Top N values for different k\", fontsize=16)\n",
        "\n",
        "for i, k in enumerate(k_category_list):\n",
        "    df_k = df[df['k'] == k]  # Filtrar por k\n",
        "\n",
        "    for j, metric in enumerate(metrics):\n",
        "        ax = axes[i, j]\n",
        "        for model in models:\n",
        "            df_model = df_k[df_k['model'] == model]\n",
        "            ax.plot(df_model['top_n'], df_model[metric], label=model, marker='o')\n",
        "\n",
        "        if i == 0:  # Títulos de las columnas (métricas)\n",
        "            ax.set_title(metric)\n",
        "\n",
        "        if j == 0:  # Etiquetas para cada fila (k)\n",
        "            ax.set_ylabel(f\"k={k}\")\n",
        "\n",
        "        ax.grid(True)\n",
        "        if i == len(k_category_list) - 1:  # Etiqueta del eje X solo en la última fila\n",
        "            ax.set_xlabel(\"Top N\")\n",
        "\n",
        "        if i == 0 and j == len(metrics) - 1:  # Solo una vez, agregar leyenda\n",
        "            ax.legend(loc='upper right', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo de diversity_scores\n",
        "diversity_scores = {}\n",
        "\n",
        "# Lista de top_n a evaluar\n",
        "top_n_list = [5, 10, 20]\n",
        "\n",
        "# Obtener todos los modelos únicos\n",
        "models = ['most_popular', 'iknn', 'deepfm', 'fastfm', 'hybrid', 'random']\n",
        "\n",
        "for model in models:\n",
        "    scores = []\n",
        "    for top_n in top_n_list:\n",
        "        # Recalcular resultados para este top_n específico\n",
        "        results = global_metrics(data_music_test, data_music_train, top_n, k=5)\n",
        "        score = results[results['model'] == model]['User_Diversity'].mean()\n",
        "        scores.append(score)\n",
        "    diversity_scores[model] = scores\n"
      ],
      "metadata": {
        "id": "LN8dbSiHqgrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Configurar el tamaño de la figura\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Definir colores para cada modelo\n",
        "colors = {\n",
        "    'hybrid': '#2355a2',       # Azul oscuro\n",
        "    'iknn': '#4ba3c7',         # Verde azulado\n",
        "    'deepfm': '#a9cce3',       # Celeste claro\n",
        "    'fastfm': '#7491bd',       # Azul grisáceo\n",
        "    'most_popular': '#f8b195', # Naranja pastel\n",
        "    'random': '#ff9aa2'        # Coral suave\n",
        "}\n",
        "\n",
        "# Configurar las posiciones de las barras\n",
        "bar_width = 0.15\n",
        "r = np.arange(len(top_n_list))\n",
        "\n",
        "# Crear barras para cada modelo\n",
        "for i, model in enumerate(models):\n",
        "    # Obtener los valores precalculados de diversity_scores\n",
        "    scores = diversity_scores[model]\n",
        "\n",
        "    # Posición de las barras para este modelo\n",
        "    bar_positions = r + bar_width * i\n",
        "\n",
        "    # Crear las barras\n",
        "    bars = plt.bar(bar_positions, scores,\n",
        "                   width=bar_width,\n",
        "                   color=colors.get(model, '#CCCCCC'),\n",
        "                   label=model)\n",
        "\n",
        "    # Añadir valores sobre las barras\n",
        "    for idx, bar in enumerate(bars):\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar_width/2., height + 0.01,\n",
        "                 f'{height:.2f}',\n",
        "                 ha='center', va='bottom',\n",
        "                 rotation=90)\n",
        "\n",
        "# Personalizar el gráfico\n",
        "plt.title('Comparación de User Diversity entre Modelos para diferentes Top N en la Música', fontsize=14, pad=20)\n",
        "plt.xlabel('Top N', fontsize=12)\n",
        "plt.ylabel('User Diversity Score', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
        "\n",
        "# Ajustar las etiquetas del eje x\n",
        "plt.xticks(r + bar_width * (len(models) - 1) / 2, top_n_list)\n",
        "\n",
        "# Añadir leyenda\n",
        "plt.legend(title='Modelos', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "# Ajustar los márgenes\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N7wg69cFqccO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar una lista para almacenar resultados de deepfm\n",
        "results_deepfm = []\n",
        "\n",
        "# Valores de N para evaluar\n",
        "top_n_values = [5, 10, 15, 20, 25, 30]\n",
        "\n",
        "# Recolectar métricas para cada valor de N\n",
        "for n in top_n_values:\n",
        "    metric_results_deepfm = deepfm_metrics(\n",
        "        data_movie_test,\n",
        "        data_movie_train,\n",
        "        n, 5,\n",
        "        beta_lt=0.4,\n",
        "        lambda_ips=0.5\n",
        "    )\n",
        "    metric_results_deepfm['N'] = n  # Agregar el valor de N\n",
        "    results_deepfm.append(metric_results_deepfm)\n",
        "\n",
        "# Convertir los resultados en un DataFrame para facilitar la visualización\n",
        "results_deepfm_df = pd.DataFrame(results_deepfm)"
      ],
      "metadata": {
        "id": "7OuY_-JSqmfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas de diversidad a graficar para deepfm\n",
        "metrics_to_plot = [\n",
        "    \"User_Diversity\", \"Long_Tail\", \"Shannon_Entropy\",\n",
        "    \"Intra_List_Diversity\", \"Diversity_Coverage\", \"MAP\",\n",
        "    \"nDCG\", \"Precision\", \"Recall\"\n",
        "]\n",
        "\n",
        "# Configurar el gráfico\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Graficar cada métrica\n",
        "for metric in metrics_to_plot:\n",
        "    plt.plot(results_deepfm_df['N'], results_deepfm_df[metric], label=metric)\n",
        "\n",
        "# Configurar título, etiquetas y leyenda\n",
        "plt.title(\"Métricas de Diversidad del Modelo DeepFM en la Música\")\n",
        "plt.xlabel(\"N (Top-N Recomendaciones)\")\n",
        "plt.ylabel(\"Valor de la Métrica\")\n",
        "plt.legend(\n",
        "    loc=\"upper left\",            # Posición base dentro del gráfico\n",
        "    bbox_to_anchor=(1.05, 1),    # Ajuste para colocarla fuera, en la esquina superior derecha\n",
        "    fontsize=10,                 # Tamaño de la fuente\n",
        "    borderaxespad=0              # Reducir espacio entre la leyenda y el gráfico\n",
        ")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7qrOPEmZqqxu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}